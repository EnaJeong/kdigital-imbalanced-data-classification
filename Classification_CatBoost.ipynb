{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "occupational-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import *\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "monthly-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-edinburgh",
   "metadata": {},
   "source": [
    "# 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subject-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./datasets/X_samples.pickle\", \"rb\") as f:\n",
    "    X_samples = pickle.load(f)\n",
    "    \n",
    "with open(f\"./datasets/y_samples.pickle\", \"rb\") as f:\n",
    "    y_samples = pickle.load(f)\n",
    "    \n",
    "with open(f\"./datasets/X_test.pickle\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "    \n",
    "with open(f\"./datasets/y_test.pickle\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cellular-carry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201810</th>\n",
       "      <td>0.579847</td>\n",
       "      <td>-0.011862</td>\n",
       "      <td>1.035499</td>\n",
       "      <td>-0.317540</td>\n",
       "      <td>0.216728</td>\n",
       "      <td>1.201270</td>\n",
       "      <td>-0.537323</td>\n",
       "      <td>1.319719</td>\n",
       "      <td>-0.189181</td>\n",
       "      <td>-0.627079</td>\n",
       "      <td>-0.131042</td>\n",
       "      <td>0.186976</td>\n",
       "      <td>0.428736</td>\n",
       "      <td>-0.650821</td>\n",
       "      <td>0.607427</td>\n",
       "      <td>-1.605008</td>\n",
       "      <td>-0.426110</td>\n",
       "      <td>-0.604022</td>\n",
       "      <td>0.099792</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.286629</td>\n",
       "      <td>0.166828</td>\n",
       "      <td>0.550873</td>\n",
       "      <td>-0.323683</td>\n",
       "      <td>-0.402491</td>\n",
       "      <td>0.195611</td>\n",
       "      <td>-0.573086</td>\n",
       "      <td>-0.079200</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>-0.254035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264506</th>\n",
       "      <td>0.901937</td>\n",
       "      <td>2.267601</td>\n",
       "      <td>-1.634754</td>\n",
       "      <td>-2.368609</td>\n",
       "      <td>-2.592182</td>\n",
       "      <td>1.161092</td>\n",
       "      <td>3.434814</td>\n",
       "      <td>-1.615728</td>\n",
       "      <td>0.797080</td>\n",
       "      <td>-1.404452</td>\n",
       "      <td>1.591339</td>\n",
       "      <td>-0.219360</td>\n",
       "      <td>-0.722225</td>\n",
       "      <td>0.316331</td>\n",
       "      <td>-0.203926</td>\n",
       "      <td>0.188359</td>\n",
       "      <td>-0.707386</td>\n",
       "      <td>0.435844</td>\n",
       "      <td>-0.286008</td>\n",
       "      <td>-0.261407</td>\n",
       "      <td>-0.343678</td>\n",
       "      <td>-0.163936</td>\n",
       "      <td>-0.078568</td>\n",
       "      <td>0.259323</td>\n",
       "      <td>0.687408</td>\n",
       "      <td>-0.131926</td>\n",
       "      <td>-0.141368</td>\n",
       "      <td>0.026772</td>\n",
       "      <td>-0.055990</td>\n",
       "      <td>0.041920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63736</th>\n",
       "      <td>-0.397573</td>\n",
       "      <td>1.118301</td>\n",
       "      <td>-1.260762</td>\n",
       "      <td>0.981093</td>\n",
       "      <td>-0.380698</td>\n",
       "      <td>-1.876228</td>\n",
       "      <td>-0.490142</td>\n",
       "      <td>-1.089500</td>\n",
       "      <td>0.062601</td>\n",
       "      <td>0.119233</td>\n",
       "      <td>0.495179</td>\n",
       "      <td>-0.818852</td>\n",
       "      <td>-1.269072</td>\n",
       "      <td>-1.259742</td>\n",
       "      <td>-0.383677</td>\n",
       "      <td>0.541024</td>\n",
       "      <td>1.271092</td>\n",
       "      <td>0.402624</td>\n",
       "      <td>-0.814504</td>\n",
       "      <td>0.430227</td>\n",
       "      <td>0.227343</td>\n",
       "      <td>0.364685</td>\n",
       "      <td>0.773901</td>\n",
       "      <td>-0.193256</td>\n",
       "      <td>0.415118</td>\n",
       "      <td>0.360261</td>\n",
       "      <td>-0.054869</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>0.043857</td>\n",
       "      <td>1.553832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241327</th>\n",
       "      <td>0.778757</td>\n",
       "      <td>2.063018</td>\n",
       "      <td>0.608260</td>\n",
       "      <td>-3.168853</td>\n",
       "      <td>0.618313</td>\n",
       "      <td>1.228515</td>\n",
       "      <td>-1.367266</td>\n",
       "      <td>0.683151</td>\n",
       "      <td>-0.308130</td>\n",
       "      <td>-0.147176</td>\n",
       "      <td>-0.859443</td>\n",
       "      <td>1.672501</td>\n",
       "      <td>0.060919</td>\n",
       "      <td>-0.917332</td>\n",
       "      <td>-2.099999</td>\n",
       "      <td>-0.637629</td>\n",
       "      <td>0.540038</td>\n",
       "      <td>1.976581</td>\n",
       "      <td>1.105321</td>\n",
       "      <td>-0.025014</td>\n",
       "      <td>-0.155587</td>\n",
       "      <td>-0.022321</td>\n",
       "      <td>0.076885</td>\n",
       "      <td>-0.042470</td>\n",
       "      <td>0.578092</td>\n",
       "      <td>0.345450</td>\n",
       "      <td>0.660782</td>\n",
       "      <td>-0.089294</td>\n",
       "      <td>-0.023863</td>\n",
       "      <td>-0.296793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271841</th>\n",
       "      <td>0.940836</td>\n",
       "      <td>-1.212528</td>\n",
       "      <td>0.730185</td>\n",
       "      <td>1.549615</td>\n",
       "      <td>-0.954037</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>-0.092019</td>\n",
       "      <td>0.124386</td>\n",
       "      <td>0.595537</td>\n",
       "      <td>-0.570630</td>\n",
       "      <td>-1.090583</td>\n",
       "      <td>0.339272</td>\n",
       "      <td>0.843626</td>\n",
       "      <td>0.394601</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>-0.512564</td>\n",
       "      <td>0.792514</td>\n",
       "      <td>-0.751414</td>\n",
       "      <td>0.277571</td>\n",
       "      <td>0.372448</td>\n",
       "      <td>-0.012042</td>\n",
       "      <td>-0.161695</td>\n",
       "      <td>-0.744489</td>\n",
       "      <td>-0.173554</td>\n",
       "      <td>-0.405409</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>-0.143519</td>\n",
       "      <td>-0.050795</td>\n",
       "      <td>0.034654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "201810  0.579847 -0.011862  1.035499 -0.317540  0.216728  1.201270 -0.537323   \n",
       "264506  0.901937  2.267601 -1.634754 -2.368609 -2.592182  1.161092  3.434814   \n",
       "63736  -0.397573  1.118301 -1.260762  0.981093 -0.380698 -1.876228 -0.490142   \n",
       "241327  0.778757  2.063018  0.608260 -3.168853  0.618313  1.228515 -1.367266   \n",
       "271841  0.940836 -1.212528  0.730185  1.549615 -0.954037  0.008643 -0.092019   \n",
       "\n",
       "              V7        V8        V9       V10       V11       V12       V13  \\\n",
       "201810  1.319719 -0.189181 -0.627079 -0.131042  0.186976  0.428736 -0.650821   \n",
       "264506 -1.615728  0.797080 -1.404452  1.591339 -0.219360 -0.722225  0.316331   \n",
       "63736  -1.089500  0.062601  0.119233  0.495179 -0.818852 -1.269072 -1.259742   \n",
       "241327  0.683151 -0.308130 -0.147176 -0.859443  1.672501  0.060919 -0.917332   \n",
       "271841  0.124386  0.595537 -0.570630 -1.090583  0.339272  0.843626  0.394601   \n",
       "\n",
       "             V14       V15       V16       V17       V18       V19       V20  \\\n",
       "201810  0.607427 -1.605008 -0.426110 -0.604022  0.099792  0.000011 -0.286629   \n",
       "264506 -0.203926  0.188359 -0.707386  0.435844 -0.286008 -0.261407 -0.343678   \n",
       "63736  -0.383677  0.541024  1.271092  0.402624 -0.814504  0.430227  0.227343   \n",
       "241327 -2.099999 -0.637629  0.540038  1.976581  1.105321 -0.025014 -0.155587   \n",
       "271841  0.266667 -0.512564  0.792514 -0.751414  0.277571  0.372448 -0.012042   \n",
       "\n",
       "             V21       V22       V23       V24       V25       V26       V27  \\\n",
       "201810  0.166828  0.550873 -0.323683 -0.402491  0.195611 -0.573086 -0.079200   \n",
       "264506 -0.163936 -0.078568  0.259323  0.687408 -0.131926 -0.141368  0.026772   \n",
       "63736   0.364685  0.773901 -0.193256  0.415118  0.360261 -0.054869  0.016690   \n",
       "241327 -0.022321  0.076885 -0.042470  0.578092  0.345450  0.660782 -0.089294   \n",
       "271841 -0.161695 -0.744489 -0.173554 -0.405409  0.217600  0.357895 -0.143519   \n",
       "\n",
       "             V28    Amount  \n",
       "201810  0.015847 -0.254035  \n",
       "264506 -0.055990  0.041920  \n",
       "63736   0.043857  1.553832  \n",
       "241327 -0.023863 -0.296793  \n",
       "271841 -0.050795  0.034654  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "external-mistake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201810    0\n",
       "264506    0\n",
       "63736     0\n",
       "241327    0\n",
       "271841    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "racial-turkish",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Raw\n",
      "====================================================================================================\n",
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "143144  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "258914  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "51111  -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "146949  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "135606 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "              V7        V8        V9       V10       V11       V12       V13  \\\n",
      "143144  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "258914 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "51111  -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "146949  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "135606  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "             V14       V15       V16       V17       V18       V19       V20  \\\n",
      "143144 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "258914 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "51111  -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "146949  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "135606 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "             V21       V22       V23       V24       V25       V26       V27  \\\n",
      "143144 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "258914 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "51111   0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "146949 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "135606 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "             V28    Amount  \n",
      "143144 -0.093342 -0.296793  \n",
      "258914 -0.041962  0.565919  \n",
      "51111   0.240607 -0.296793  \n",
      "146949  0.223898 -0.237546  \n",
      "135606  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0    227447\n",
      "1       398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 227845\n",
      "0 비율 :  99.83 %\n",
      "1 비율 :   0.17 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "SMOTE\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "1  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "2 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "3  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "1 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "2 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "3  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "1 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "2 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "3  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "1 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "2  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "3 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0 -0.093342 -0.296793  \n",
      "1 -0.041962  0.565919  \n",
      "2  0.240607 -0.296793  \n",
      "3  0.223898 -0.237546  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0    227447\n",
      "1    227447\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 454894\n",
      "0 비율 :  50.00 %\n",
      "1 비율 :  50.00 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "ADASYN\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "1  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "2 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "3  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "1 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "2 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "3  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "1 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "2 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "3  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "1 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "2  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "3 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0 -0.093342 -0.296793  \n",
      "1 -0.041962  0.565919  \n",
      "2  0.240607 -0.296793  \n",
      "3  0.223898 -0.237546  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    227453\n",
      "0    227447\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 454900\n",
      "1 비율 :  50.00 %\n",
      "0 비율 :  50.00 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "CNN\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.989403 -0.147206  1.099073 -0.448814 -0.670465  0.813368 -0.624680   \n",
      "1  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "2  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "3 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.824100  0.068627 -0.036771 -0.339651  1.049736  0.317577 -0.675746   \n",
      "1  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "2 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "3 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -0.768674 -0.869056  0.497980  0.186416  0.290770 -0.013677  0.109644   \n",
      "1 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "2 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "3 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.320720 -0.768440  0.111616  0.642187 -0.437602  0.093575  0.327780   \n",
      "1 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "2 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "3  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0  0.130896 -0.211835  \n",
      "1 -0.093342 -0.296793  \n",
      "2 -0.041962  0.565919  \n",
      "3  0.240607 -0.296793  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0    908\n",
      "1    398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 1306\n",
      "0 비율 :  69.53 %\n",
      "1 비율 :  30.47 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "SMOTE + ENN\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "1  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "2 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "3  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "1 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "2 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "3  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "1 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "2 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "3  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "1 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "2  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "3 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0 -0.093342 -0.296793  \n",
      "1 -0.041962  0.565919  \n",
      "2  0.240607 -0.296793  \n",
      "3  0.223898 -0.237546  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    227447\n",
      "0    227056\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 454503\n",
      "1 비율 :  50.04 %\n",
      "0 비율 :  49.96 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "ADASYN + ENN\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "1  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "2 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "3  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "1 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "2 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "3  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "1 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "2 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "3  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "1 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "2  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "3 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0 -0.093342 -0.296793  \n",
      "1 -0.041962  0.565919  \n",
      "2  0.240607 -0.296793  \n",
      "3  0.223898 -0.237546  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    227453\n",
      "0    227056\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 454509\n",
      "1 비율 :  50.04 %\n",
      "0 비율 :  49.96 %\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for key, sample in X_samples.items():\n",
    "    y = y_samples[key]\n",
    "    total = len(y)\n",
    "    counts = y.value_counts()\n",
    "    \n",
    "    print('=' * 100)\n",
    "    print(key)\n",
    "    print('=' * 100)\n",
    "    print(sample.head())\n",
    "    print('-' * 100)\n",
    "    print(counts)\n",
    "    print('-' * 30)\n",
    "    print(f\"Total : {total}\")\n",
    "    for idx in counts.index:\n",
    "        print(f\"{idx} 비율 : {counts[idx] / total * 100:6.2f} %\")\n",
    "    print('=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-electron",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quantitative-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data_info(y):\n",
    "    total = len(y)\n",
    "    counts = y.value_counts()\n",
    "    print('=' * 80)\n",
    "    print(counts)\n",
    "    print('-' * 30)\n",
    "    for idx in counts.index:\n",
    "        print(f\"{idx} 비율 : {counts[idx] / total * 100:6.2f} %\")\n",
    "    print('=' * 80)\n",
    "\n",
    "def evaluate_model(clf, x_test, y_test):\n",
    "    y_proba = clf.predict_proba(x_test)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    fl = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "    \n",
    "    print('=' * 80)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('-' * 60)\n",
    "    print(f'Accuracy  : {accuracy}')\n",
    "    print(f'Precision : {precision}')\n",
    "    print(f'Recall    : {recall}')\n",
    "    print(f'F1-Score  : {fl}')\n",
    "    print('-' * 60)\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print('-' * 60)\n",
    "    print(f'ROC AUC : {roc_auc}')\n",
    "    print('=' * 80)\n",
    "    \n",
    "    return accuracy, precision, recall, fl, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recreational-absolute",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Raw\n",
      "================================================================================\n",
      "0    227447\n",
      "1       398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  99.83 %\n",
      "1 비율 :   0.17 %\n",
      "================================================================================\n",
      "CatBoost Raw\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56866     2]\n",
      " [   25    69]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995259997893332\n",
      "Precision : 0.971830985915493\n",
      "Recall    : 0.7340425531914894\n",
      "F1-Score  : 0.8363636363636363\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.97      0.73      0.84        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.87      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9760256675032438\n",
      "================================================================================\n",
      "================================================================================\n",
      "SMOTE\n",
      "================================================================================\n",
      "0    227447\n",
      "1    227447\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  50.00 %\n",
      "1 비율 :  50.00 %\n",
      "================================================================================\n",
      "CatBoost SMOTE\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56801    67]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9985077771145676\n",
      "Precision : 0.5314685314685315\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.6413502109704642\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.53      0.81      0.64        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.77      0.90      0.82     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9765169133746084\n",
      "================================================================================\n",
      "================================================================================\n",
      "ADASYN\n",
      "================================================================================\n",
      "1    227453\n",
      "0    227447\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "1 비율 :  50.00 %\n",
      "0 비율 :  50.00 %\n",
      "================================================================================\n",
      "CatBoost ADASYN\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56763   105]\n",
      " [   16    78]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9978757768336786\n",
      "Precision : 0.4262295081967213\n",
      "Recall    : 0.8297872340425532\n",
      "F1-Score  : 0.5631768953068592\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.43      0.83      0.56        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.71      0.91      0.78     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9807061593926361\n",
      "================================================================================\n",
      "================================================================================\n",
      "CNN\n",
      "================================================================================\n",
      "0    908\n",
      "1    398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  69.53 %\n",
      "1 비율 :  30.47 %\n",
      "================================================================================\n",
      "CatBoost CNN\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56856    12]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9994733330992591\n",
      "Precision : 0.8636363636363636\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.8351648351648351\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.86      0.81      0.84        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.90      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9779863483782525\n",
      "================================================================================\n",
      "================================================================================\n",
      "SMOTE + ENN\n",
      "================================================================================\n",
      "1    227447\n",
      "0    227056\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "1 비율 :  50.04 %\n",
      "0 비율 :  49.96 %\n",
      "================================================================================\n",
      "CatBoost SMOTE + ENN\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56789    79]\n",
      " [   16    78]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9983322214809873\n",
      "Precision : 0.4968152866242038\n",
      "Recall    : 0.8297872340425532\n",
      "F1-Score  : 0.6215139442231075\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.50      0.83      0.62        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.75      0.91      0.81     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9766699366506086\n",
      "================================================================================\n",
      "================================================================================\n",
      "ADASYN + ENN\n",
      "================================================================================\n",
      "1    227453\n",
      "0    227056\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "1 비율 :  50.04 %\n",
      "0 비율 :  49.96 %\n",
      "================================================================================\n",
      "CatBoost ADASYN + ENN\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56796    72]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9984375548611355\n",
      "Precision : 0.5167785234899329\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.6337448559670781\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.52      0.82      0.63        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.76      0.91      0.82     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9767788114019925\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "clfs, results = {}, {}\n",
    "accuracies, precisions, recalls, f1_scores, roc_aucs = {}, {}, {}, {}, {}\n",
    "\n",
    "for key, X in X_samples.items():\n",
    "    y = y_samples[key]\n",
    "    \n",
    "    print('=' * 80)\n",
    "    print(key)\n",
    "    show_data_info(y)\n",
    "    \n",
    "    clf = CatBoostClassifier(learning_rate=0.1, eval_metric='F1', early_stopping_rounds=100, verbose=False)\n",
    "    clf.fit(X, y, eval_set=(X_test, y_test))\n",
    "    \n",
    "    print(f'CatBoost {key}')\n",
    "    result = evaluate_model(clf, X_test, y_test)\n",
    "    \n",
    "    clfs[key] = clf\n",
    "    results[key] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "august-advance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Raw\n",
      "================================================================================\n",
      "0    227447\n",
      "1       398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  99.83 %\n",
      "1 비율 :   0.17 %\n",
      "================================================================================\n",
      "CatBoost Balanced\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[54916  1952]\n",
      " [   10    84]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9655559846915488\n",
      "Precision : 0.0412573673870334\n",
      "Recall    : 0.8936170212765957\n",
      "F1-Score  : 0.07887323943661971\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     56868\n",
      "           1       0.04      0.89      0.08        94\n",
      "\n",
      "    accuracy                           0.97     56962\n",
      "   macro avg       0.52      0.93      0.53     56962\n",
      "weighted avg       1.00      0.97      0.98     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9691341015176618\n",
      "================================================================================\n",
      "================================================================================\n",
      "Raw\n",
      "================================================================================\n",
      "0    227447\n",
      "1       398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  99.83 %\n",
      "1 비율 :   0.17 %\n",
      "================================================================================\n",
      "CatBoost SqrtBalanced\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56862     6]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995962220427653\n",
      "Precision : 0.927710843373494\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.8700564971751413\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.93      0.82      0.87        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.96      0.91      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9836697226425062\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "class_weights = ['Balanced', 'SqrtBalanced']\n",
    "\n",
    "for class_weight in class_weights:\n",
    "    X, y = X_samples['Raw'], y_samples['Raw']\n",
    "    \n",
    "    print('=' * 80)\n",
    "    print('Raw')\n",
    "    show_data_info(y)\n",
    "    \n",
    "    clf = CatBoostClassifier(learning_rate=0.1, eval_metric='F1', auto_class_weights=class_weight,\n",
    "                             early_stopping_rounds=100, verbose=False)\n",
    "    clf.fit(X, y, eval_set=(X_test, y_test))\n",
    "    \n",
    "    print(f'CatBoost {class_weight}')\n",
    "    result = evaluate_model(clf, X_test, y_test)\n",
    "    \n",
    "    clfs[class_weight] = clf\n",
    "    results[class_weight] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "perfect-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw</th>\n",
       "      <th>SMOTE</th>\n",
       "      <th>ADASYN</th>\n",
       "      <th>CNN</th>\n",
       "      <th>SMOTE + ENN</th>\n",
       "      <th>ADASYN + ENN</th>\n",
       "      <th>Balanced</th>\n",
       "      <th>SqrtBalanced</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.998508</td>\n",
       "      <td>0.997876</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>0.998332</td>\n",
       "      <td>0.998438</td>\n",
       "      <td>0.965556</td>\n",
       "      <td>0.999596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.531469</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.496815</td>\n",
       "      <td>0.516779</td>\n",
       "      <td>0.041257</td>\n",
       "      <td>0.927711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.819149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.641350</td>\n",
       "      <td>0.563177</td>\n",
       "      <td>0.835165</td>\n",
       "      <td>0.621514</td>\n",
       "      <td>0.633745</td>\n",
       "      <td>0.078873</td>\n",
       "      <td>0.870056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC_AUC</th>\n",
       "      <td>0.976026</td>\n",
       "      <td>0.976517</td>\n",
       "      <td>0.980706</td>\n",
       "      <td>0.977986</td>\n",
       "      <td>0.976670</td>\n",
       "      <td>0.976779</td>\n",
       "      <td>0.969134</td>\n",
       "      <td>0.983670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Raw     SMOTE    ADASYN       CNN  SMOTE + ENN  ADASYN + ENN  \\\n",
       "Score                                                                          \n",
       "Accuracy   0.999526  0.998508  0.997876  0.999473     0.998332      0.998438   \n",
       "Precision  0.971831  0.531469  0.426230  0.863636     0.496815      0.516779   \n",
       "Recall     0.734043  0.808511  0.829787  0.808511     0.829787      0.819149   \n",
       "F1-Score   0.836364  0.641350  0.563177  0.835165     0.621514      0.633745   \n",
       "ROC_AUC    0.976026  0.976517  0.980706  0.977986     0.976670      0.976779   \n",
       "\n",
       "           Balanced  SqrtBalanced  \n",
       "Score                              \n",
       "Accuracy   0.965556      0.999596  \n",
       "Precision  0.041257      0.927711  \n",
       "Recall     0.893617      0.819149  \n",
       "F1-Score   0.078873      0.870056  \n",
       "ROC_AUC    0.969134      0.983670  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC_AUC']\n",
    "    \n",
    "evaluation = pd.DataFrame(results, index=cols)\n",
    "evaluation.index.set_names('Score', inplace=True)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "offensive-airline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFiCAYAAAAEBkVdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1l0lEQVR4nO3de3hU5bn38d+dhKNEIYBAORRUziAKEVutFg94KiiCJ8Bia93BVyN4aAWrxZbd7ZZ6qIAIKm03IluFV6uAtp6r5VVEhEIIBEQEIYAEQkk4JCHkfv+YGTpdBDLAkMnA93NduZz1rGetuYe5TH7zzLOeZe4uAAAAAP+SkugCAAAAgJqGkAwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAALSEvXETZo08bZt2ybq6QEAAGL2xRdfbHX3pomuA9UnYSG5bdu2WrhwYaKeHgAAIGZmti7RNaB6Md0CAAAACCAkAwAAAAGEZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEBAlSHZzP5oZlvMbNlB9puZTTCz1Wa21Mx6xr9MAAAAoPrEMpL8P5KuOMT+KyW1D/9kSZp89GUBAAAAiVNlSHb3jyUVHqLLNZJe8JD5khqaWYt4FQgAAABUt7Q4nKOlpPVR2xvCbZuCHc0sS6HRZrVp0yYOTx27tqPfrLLP2kd/FLfnW9Gpc5V9OuetiNvzAQAAIH7iEZKtkjavrKO7PyfpOUnKzMystE9C/fqUmLp1b1d1wJ8Zw3km3f5BTM9Xsv3JKvvc98rcmM4FAACAqsVjdYsNklpHbbeStDEO5wUAAAASIh4hebakYeFVLr4naYe7HzDVAgAAAEgWVU63MLOXJPWR1MTMNkh6WFItSXL3KZLeknSVpNWSdkv66bEqFgAAAKgOVYZkdx9cxX6XdGfcKgIAADVK92ndq+yTc0tONVQCVJ94XLgHAABqoJhWdqo7pOoTxXDBeiyrOknSB30mVdmHC9ZRExCSkRSqewk/AABwYovHhXsAAADAcYWQDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAgjJAAAAQAAhGQAAAAggJAMAAAABhGQAAAAggJAMAAAABBCSAQAAgABCMgAAABBASAYAAAACCMkAAABAACEZAAAACCAkAwAAAAGEZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEAAIRkAAAAIICQDAAAAAYRkAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQkJboAoCaaEWnzlX26Zy3ohoqAQAAicBIMgAAABBASAYAAAACCMkAAABAACEZAAAACCAkAwAAAAGEZAAAACCAJeAAAAfVdvSbVfZZ++iP4vZ8LL8IoKYgJANIGt2nda+yT84tOTGda9LtH1TZ584pF8d0LgDA8YfpFgAAAEAAIRkAAAAIYLoFABzEEzf2q7LPfa/MrYZKAADVjZFkAAAAICCmkGxmV5jZSjNbbWajK9l/ipnNMbMlZpZrZj+Nf6kAAABA9ahyuoWZpUqaJKmvpA2SPjez2e6+PKrbnZKWu3t/M2sqaaWZzXD3smNSNYDjz69PqbpPuzZVdollCTFJUp9JsfUDAJyQYhlJ7i1ptbuvCYfelyVdE+jjktLNzCQ1kFQoqTyulQIAAADVJJaQ3FLS+qjtDeG2aE9L6ixpo6QcSSPdvSJ4IjPLMrOFZrawoKDgCEsGAAAAjq1YQrJV0uaB7csl/UPSdySdJelpMzv5gIPcn3P3THfPbNq06WGWCgAAAFSPWELyBkmto7ZbKTRiHO2nkl7zkNWSvpbUKT4lAgAAANUrlpD8uaT2ZtbOzGpLuknS7ECfbyRdIklm1kxSR0lr4lkoAAAAUF2qXN3C3cvNLFvS25JSJf3R3XPN7Pbw/imS/lPS/5hZjkLTM0a5+9ZjWDcAAABwzMR0xz13f0vSW4G2KVGPN0q6LL6lAQAAAInBHfcAAACAAEIyAAAAEEBIBgAAAAIIyQAAAEAAIRkAAAAIICQDAAAAAYRkAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAtISXQCA41vb0W/G1G9t3WNcCAAAh4GRZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEAAIRkAAAAIICQDAAAAAYRkAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAgjJAAAAQAAhGQAAAAggJAMAAAABhGQAAAAggJAMAAAABBCSAQAAgABCMgAAABBASAYAAAACCMkAAABAACEZAAAACEhLdAEAgCT361Ni7Lfj2NYBAHHESDIAAAAQwEgyAOC488SN/WLqd98rc49xJQCSFSPJAAAAQAAhGQAAAAhgugUAIKlMuv2DRJcA4ATASDIAAAAQQEgGAAAAAmIKyWZ2hZmtNLPVZjb6IH36mNk/zCzXzD6Kb5kAAABA9alyTrKZpUqaJKmvpA2SPjez2e6+PKpPQ0nPSLrC3b8xs1OPUb0AAADAMRfLSHJvSavdfY27l0l6WdI1gT5DJL3m7t9IkrtviW+ZAAAAQPWJJSS3lLQ+antDuC1aB0mNzOxvZvaFmQ2r7ERmlmVmC81sYUFBwZFVDAAAABxjsYRkq6TNA9tpknpJ+pGkyyX9ysw6HHCQ+3PununumU2bNj3sYgEAAIDqEMs6yRsktY7abiVpYyV9trr7Lkm7zOxjST0krYpLlQAAAEA1imUk+XNJ7c2snZnVlnSTpNmBPm9IusDM0sysvqRzJa2Ib6kAAABA9ahyJNndy80sW9LbklIl/dHdc83s9vD+Ke6+wsz+KmmppApJU9192bEsHAAAADhWYrottbu/JemtQNuUwPZjkh6LX2kAAABAYnDHPQAAACCAkAwAAAAEEJIBAACAgJjmJAMAcLS6T+teZZ+Z1VAHAMSCkWQAAAAggJAMAAAABBCSAQAAgABCMgAAABBASAYAAAACCMkAAABAACEZAAAACCAkAwAAAAHcTATHj1+fEkOfHce+DgAAkPQYSQYAAAACCMkAAABAANMtgGPoiRv7VdnnvlfmVkMlAADgcDCSDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAgjJAAAAQACrWwBHaNLtHyS6BAAAcIwwkgwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEAAIRkAAAAIICQDAAAAAYRkAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAgjJAAAAQAAhGQAAAAggJAMAAAABhGQAAAAggJAMAAAABKQlugCgOnWf1j2mfjOPcR0AAKBmYyQZAAAACCAkAwAAAAExhWQzu8LMVprZajMbfYh+55jZPjO7Ln4lAgAAANWrypBsZqmSJkm6UlIXSYPNrMtB+o2T9Ha8iwQAAACqUywjyb0lrXb3Ne5eJullSddU0u8uSa9K2hLH+gAAAIBqF0tIbilpfdT2hnDbfmbWUtK1kqbErzQAAAAgMWIJyVZJmwe2n5I0yt33HfJEZllmttDMFhYUFMRYIgAAAFC9YlkneYOk1lHbrSRtDPTJlPSymUlSE0lXmVm5u78e3cndn5P0nCRlZmYGgzYAAABQI8QSkj+X1N7M2knKl3STpCHRHdy9XeSxmf2PpLnBgAwAAAAkiypDsruXm1m2QqtWpEr6o7vnmtnt4f3MQwYAAMBxJabbUrv7W5LeCrRVGo7d/SdHXxYAAACQONxxDwAAAAggJAMAAAABhGQAAAAggJAMAAAABBCSAQAAgICYVrcAAADAgb744otT09LSpkrqJgYfk02FpGXl5eW39erVa0twJyEZAADgCKWlpU1t3rx556ZNm25PSUnhbsJJpKKiwgoKCrps3rx5qqSrg/v5xAMAAHDkujVt2rSIgJx8UlJSvGnTpjsU+hbgwP3VXA8AAMDxJIWAnLzC712leZiQDAAAAAQwJxkAACBO2o5+s1c8z7f20R99UVWf1NTUXu3bt9+zb98+a926denMmTO/btKkyb541nEiYiQZAAAgidWpU6ciLy9v+ZdffpnbsGHD8scee6xpoms6HhCSAQAAjhPf+973duXn59eWpA8//LD+2Wef3alz585dzj777E5LliypI0k//OEPz/jss8/qSVLnzp27/PznP28hSSNHjvzOk08+2SRx1dcshGQAAIDjQHl5uT788MP0AQMG/FOSevToUbJgwYK8FStWLH/44Yfz77///laSdP755+/84IMPGhQWFqakpqb6/PnzG0jS/PnzG1xyySXFCXwJNQpzkgEAAJJYaWlpSqdOnbrk5+fX7tat2+4BAwYUSVJhYWHqjTfe2G7t2rV1zcz37t1rktSnT5/i8ePHNzvttNPKLrvssh1/+9vfTi4uLk7ZsGFDnR49epQm9tXUHIwkAwAAJLHInOS1a9fmlJWV2aOPPnqqJI0aNarlD3/4w+Ivv/wyd86cOavLyspSJOnCCy/cvXTp0voff/xxgz59+hR369Zt91NPPdWke/fuuxL7SmoWQjIAAMBxoHHjxvsmTJjwzaRJk5qVlpZaUVFRaqtWrcok6dlnn90/17hu3breokWLvbNnz2500UUX7brggguKJ02a1Pz888/fmbjqax6mWwAAAMRJLEu2HUvnn3/+ns6dO++ZOnVqo1GjRm2+7bbb2k2YMKH5BRdcUBTd7/vf/37xxx9/fHJ6enpF3759d2ZlZdW66KKLCMlRCMkAAABJbPfu3Yujtz/44IPVkcdr165dFnk8fvz4jYHHGyWpbdu2e909oeG+JmK6BQAAABBASAYAAAACCMkAAABAACEZAAAACCAkAwAAAAGEZAAAACCAJeAAAADi5den9Irv+XZUuTTbqFGjmr/66quNU1JSPCUlRc8888y60aNHt1q/fn3t/Pz8nJSU0JjopZdeevonn3xycmTJuIULF9bNzs5us3nz5trurhtuuGHbuHHjNk2cOLHx5MmTm0nSV199Vbddu3YlKSkpuvjii3d06tSp5OGHH27VrFmzvZHnnzFjxppevXqVxPV11wCEZAAAgCT13nvvnfT22283zMnJWV6vXj3ftGlTWmlpqUlSenr6vnfffbfB5ZdfvnPr1q2pW7ZsqRU5bufOnXbttdeeMX78+G8GDhxYVFxcnPKjH/3o9HHjxjV94IEHCkaOHLlNklq2bNn9o48+WtWiRYtySZowYULj/v37b3/hhRe+Scwrrj5MtwAAAEhS+fn5tTIyMsrr1avnktSiRYvytm3b7pWkgQMHFs6YMSNDkl588cWG/fv3/2fkuOeff75xZmbmzoEDBxZJUnp6esXkyZO/GT9+fIsEvIwaiZAMAACQpAYMGFC0cePG2m3btu128803t3nzzTcbRPZddtllxfPnz29QXl6uWbNmZQwbNqwwsi83N7duz549d0efq2vXrqW7d+9OKSwsPGQ+nDNnTqNOnTp1ifzs3LnT4v/KEo/pFgAAAEnqlFNOqVi2bNnyv/71r+nvv/9++i233HL6mDFjNkhSWlqa9+7de+fUqVMzSkpKUjp27FgWOc7dzazybHuw9ogTZboFIRkAACCJpaWlqV+/fsX9+vUrPvPMM/dMnz69cWTf0KFDCwcPHnzGL37xi43Rx3Tt2nXP3//+9wbRbcuXL69dv379ikaNGlVUV+01GdMtAAAAktSSJUvq5OTk1IlsL168uF6rVq32jxhffvnlO0eMGLHp1ltvLYw+Lisra9vnn3+e/vrrr6dLoQv57rzzzjZ33XXX5uqrvmZjJBkAACBeYliyLZ6KiopSR4wY0aaoqCg1NTXV27ZtWzpt2rR111xzzemSlJKSorFjx34bPK5Bgwb+2muvrc7Ozm5z991316qoqND111+/7YEHHthS1XOG5yTvH4WeOHHiur59++6K7ytLPEIyAABAkrrgggt2L168OC/YvmDBgpWV9Y+skSxJvXv33nOwfhH5+fk50dsjRozYNmLEiG1HWm8yYboFAAAAEEBIBgAAAAIIyQAAAEAAIRkAAAAIICQDAAAAAYRkAAAAIIAl4AAAAOKk+7TuveJ5vpxbcmJad/mFF15oeMstt5y+aNGi3LPPPrtk5cqVtXv06NGtXbt2JaWlpXbSSSdVZGVlbbnrrrv+bfm2jh07dunQocOeOXPmfB1pe//990+65557WpeVlaWUlZXZgAEDtg8ZMqTwuuuuO2PZsmW5DRo0cEnq06fPGUOGDNlWUlKScvfdd7f99NNPl5977rl7JKl9+/Zd586d+2X0rbCTDSPJAAAASe7ll1/O6Nmz587p06dnRNpat25dumLFiuVr1qzJfeWVV76aNGlSs/Hjx++/ZfWiRYvqurs+++yz9KKiov2Z8Gc/+1m7Z599dl1eXt7yVatW5Q4dOrQwMzOz5Kqrrtr+y1/+soUkTZ8+veHevXstKytruyQ1a9asbOzYsS2q8zUfa4RkAACAJLZjx46UhQsXNvjTn/609s9//nOjyvp06dKl7He/+936KVOmNIu0TZs2LeOGG27YduGFFxa99NJLDSPthYWFaW3atNkrSWlpaerVq1eJJI0bN27T7NmzMz755JN6Y8aMaTllypRvIsdccsklO1atWlVvyZIldXSciCkkm9kVZrbSzFab2ehK9g81s6Xhn0/MrEf8SwUAAEDQjBkzGvbp02fHmWeeWdqwYcN98+bNq19Zv/POO2/3119/XTey/cYbb2QMGzZs+5AhQwpfeeWV/SPQWVlZ33bu3Llb3759T3/sscea7N692yQpPT294pFHHll/2WWXdbr22mu3d+/evTRyTEpKikaOHLn5N7/5zXEzmlxlSDazVEmTJF0pqYukwWbWJdDta0k/dPczJf2npOfiXSgAAAAONHPmzIzBgwdvl6RBgwYVRk+5iObu+x9/9NFH9TMyMso7dOhQdvXVVxfl5ubWLygoSJWkxx9/fNOnn3664tJLLy2aOXNm4z59+nSIHDdkyJAd6enp5ffdd9+W4PmHDx++bdGiRQ3y8vJqx/1FJkAsF+71lrTa3ddIkpm9LOkaScsjHdz9k6j+8yW1imeRAAAAONDmzZtT58+ff/KqVavqZWdna9++fWZmfs899xwQYj/99NP6p5122h5Jmj59esaaNWvqtmzZsrsk7dq1K3X69OmN7r333q2S1LVr19KuXbsW3HvvvQWNGzc+a/PmzanNmzffJ4VGjVNSDhxnrVWrlrKzszePHTu2+TF90dUklukWLSWtj9reEG47mJ9J+ktlO8wsy8wWmtnCgoKC2KsEAADAAaZPn95o4MCB2zZu3JiTn5+fs3nz5qWtWrUqW7t27b+N5q5cubL26NGjWw0fPnzLvn37NHfu3IzFixfn5ufn5+Tn5+e89NJLq2fNmpUhSS+//PIpFRUVkqScnJy6qamp3qRJk32x1JOdnb1t3rx5JxcWFib9CmqxvACrpM0raZOZXaRQSP5BZfvd/TmFp2JkZmZWeg4AAIBkFeuSbfEya9asxvfff/+m6LZrrrlm+yOPPNJi/fr1dTp37twlsgTc8OHDt4wcOXLb3Llz05s1a1bWrl27vZFjrrzyyuJbb7213bp162q9+OKLjUePHt26bt26FWlpaT516tSv09Jiy7x169b1rKysLb/61a9ax/mlVrtYXvEGSdEvtJWkjcFOZnampKmSrnT3bcH9AAAAiK8FCxasDLY99NBDWx566KEDpltE9OvXr7hfv3550W1paWkqKChYKklz585dc6jnzM/Pz4neHjFixDZJ+7NfVc+fLGKZbvG5pPZm1s7Maku6SdLs6A5m1kbSa5J+7O6r4l8mAAAAUH2qHEl293Izy5b0tqRUSX9091wzuz28f4qkMZIaS3rGzCSp3N0zj13ZAAAAwLET0wQTd39L0luBtilRj2+TdFt8SwMAAAASgzvuAQAAAAGEZAAAACCAkAwAAAAEJP1CzwAAADXFik6de8XzfJ3zVlS57vI333yTdscdd7RZsmRJ/dq1a3urVq1KJ06cuL5Hjx7dfvvb365/8MEHt0jSsGHD2mRmZu4aMWLEtkGDBrX9+9//fvK6dety6tWr55s2bUrLzMzsHFze7UTGSDIAAECSqqio0NVXX33GhRdeWLx+/fplX331Ve5///d/52/cuLFWRkZG+bPPPntqSUlJZTeGU2pqqk+YMKFJddecLAjJAAAASWru3LnpaWlpfv/99xdE2s4777w97dq1K8vIyCj/wQ9+UDxp0qTGlR07fPjwLZMnT262d+/eynaf8AjJAAAASWrp0qX1evTosftg+8eMGbPp6aefblZeXn7Avu9+97tl55xzzs5nnnmm0hB9oiMkAwAAHKc6depUdtZZZ+169tlnMyrb//DDD2+aMGFC84qKiuourcYjJAMAACSp7t2771myZEn9Q/UZM2bM5qeeeqpFZUG4W7dupV26dNk9bdq0RsesyCRFSAYAAEhS/fv3Ly4rK7Mnnnhi/wV4H330Uf3Vq1fXjmyfffbZJe3bt9/z/vvvn1LZOR5++OFNkyZNal4d9SYTloADAACIk1iWbIunlJQUzZ49+6s77rij9VNPPdW8Tp06+5eAi+73q1/9atP555/fpbJzZGZmlnTt2nV3bm7uIUekTzSEZAAAgCTWtm3bvW+99daaYPuXX36ZG3n8/e9/f09FRcX+AP/qq6+uje77zjvvfHVMi0xCTLcAAAAAAgjJAAAAQAAhGQAAAAggJAMAAAABhGQAAAAggJAMAAAABLAEHAAAQJxMuv2DXvE8351TLq5y3eVRo0Y1f/XVVxunpKR4SkqKnnnmmXUXX3zxrt69e3dcv3597fz8/JyUlNC46KWXXnr6J598cvLu3bsXS9LChQvrZmdnt9m8eXNtd9cNN9ywbdy4cZsmTpzYePLkyc0k6auvvqrbrl27kpSUFF188cU7OnXqVPLwww+3atas2d5IDTNmzFjTq1evkiN9nffee+93XnzxxSYZGRnlkbZ58+atnD9/fv3+/ft3mDFjxuohQ4bskKSLLrrojPvuu+/bfv36Fffu3bvj7t27U5YtW7ZCkj7++OP6P//5z1svWLBg5ZHWEsFIMgAAQJJ67733Tnr77bcb5uTkLF+1atXyDz/8cNVpp51WFtmfnp6+7913320gSVu3bk3dsmVLrci+nTt32rXXXnvG/fffv3nt2rXLli1btvyzzz5rMG7cuKYjR47clpeXtzwvL2/5qaeeuvejjz5alZeXt/yZZ57Jl6T+/ftvj+zPy8tbfqiAPHfu3PRBgwa1req13H777d9Gn7NJkyb7JKlZs2Z7x40b1+Jgx23bti1t5syZJ8f0D3YYCMkAAABJKj8/v1ZGRkZ5vXr1XJJatGhR3rZt2/0jvAMHDiycMWNGhiS9+OKLDfv37//PyL7nn3++cWZm5s6BAwcWSVJ6enrF5MmTvxk/fvxBA2kidO7ceXd6evq+P//5z5UG4ezs7G8fffTR78T7eQnJAAAASWrAgAFFGzdurN22bdtuN998c5s333yzQfT+yy67rHj+/PkNysvLNWvWrIxhw4YVRvbl5ubW7dmz5+7o/l27di3dvXt3SmFh4SEz4pw5cxp16tSpS+Rn586ddrSvZcqUKc0i5zv33HM7RO976KGHNj3yyCOVhvcLLrhgZ+3atSvmzJmTfrQ1RCMkAwAAJKlTTjmlYtmyZcuffvrpdU2bNi2/5ZZbTp8wYULjyP60tDTv3bv3zqlTp2aUlJSkdOzYcf9UDHc3s8qz7cHaI4LTLRo0aODBPmeeeWanTp06dbnjjju++9577zWMBOBXX3210hHh6OkWn3322arofVdcccVOSfrrX//aoLJjf/nLXx40RB8pQjIAAEASS0tLU79+/Yp///vfb3zssce+ef311xtF7x86dGjh6NGj2wwcOHB7dHvXrl33fPHFF/Wj25YvX167fv36FY0aNao42rqWLl2aF57HvO7SSy/9ZyQADxo0qOhIzvfAAw9s+q//+q9Kg/DVV19dXFpamjJv3ryTjq7qfyEkAwAAJKklS5bUycnJqRPZXrx4cb1WrVqVRfe5/PLLd44YMWLTrbfeWhjdnpWVte3zzz9Pf/3119Ol0IV8d955Z5u77rprc/VUf3gGDhxYtGPHjtQVK1bUr2z/qFGjNk2cOLF5vJ6PJeAAAADiJJYl2+KpqKgodcSIEW2KiopSU1NTvW3btqXTpk1bF90nJSVFY8eO/TZ4bIMGDfy1115bnZ2d3ebuu++uVVFRoeuvv37bAw88sKWq5w3PSd4/9WHixInr+vbtu+toXsuUKVOazZw5c/9UkTfeeGN1sM+oUaM23XzzzWdUdvyNN964Y+zYseWV7TsShGQAAIAkdcEFF+xevHhxXmX7DrZWcGSNZEnq3bv3nqrWFM7Pz8+J3h4xYsS2ESNGbIu1xn79+hX369ev+FB9nnzyyY1PPvnkxmB7x44dy6KPHTp06I6hQ4fu/yASrD03N3dFrHVVhekWAAAAQAAhGQAAAAggJAMAAAABhGQAAAAggJAMAAAABBCSAQAAgACWgAMAAIiTJ27s1yue57vvlbkxrbv8wgsvNLzllltOX7RoUe7ZZ59dIkkrV66s3aNHj27t2rUrKS0ttZNOOqkiKytry1133fVvy7d17NixS4cOHfbMmTPn60jb+++/f9I999zTuqysLKWsrMwGDBiwfciQIYXXXXfdGcuWLcuN3Ia6T58+ZwwZMmRbSUlJyt133932008/XX7uuefukaT27dt3nTt37pfRt8I+XHPnzk0fPHjw6S1bttx/jkcffXT9gAEDis2s12233fbt888/v0GSxowZ02znzp2pTz755MZ77733O5MnT262evXqnJYtW5ZLUv369c+OXv6uKowkAwAAJLmXX345o2fPnjunT5+eEd3eunXr0hUrVixfs2ZN7iuvvPLVpEmTmo0fP37/DTsWLVpU19312WefpRcVFe3PhT/72c/aPfvss+vy8vKWr1q1Knfo0KGFmZmZJVddddX2X/7yly0kafr06Q337t1rWVlZ2yWpWbNmZWPHjq30ttEH07Jly+5V9cnMzNwZuaV1Xl7e8gEDBhRLUu3atf2tt95qtGnTpkoHfRs2bFj+29/+ttnh1BONkAwAAJDEduzYkbJw4cIGf/rTn9b++c9/bnSwfl26dCn73e9+t37KlCn7g+O0adMybrjhhm0XXnhh0UsvvdQw0l5YWJjWpk2bvZKUlpamXr16lUjSuHHjNs2ePTvjk08+qTdmzJiWU6ZM+SZyzCWXXLJj1apV9ZYsWVJH1SA1NdWHDRtW8Mgjj1QahAcPHrxt9uzZGd9++23qkZyfkAwAAJDEZsyY0bBPnz47zjzzzNKGDRvumzdvXv2D9T3vvPN2f/3113Uj22+88UbGsGHDtg8ZMqTwlVde2T8KnZWV9W3nzp279e3b9/THHnusye7du02S0tPTKx555JH1l112Wadrr712e/fu3Usjx6SkpGjkyJGbf/Ob3xzWaHJVFi5c2KBTp05dIj+5ubn7Q/gvfvGLLa+99lrGtm3bDgjCDRo02Dd48OCtjz766BGNJhOSAQAAktjMmTMzBg8evF2SBg0aVBicchHN3fc//uijj+pnZGSUd+jQoezqq68uys3NrV9QUJAqSY8//vimTz/9dMWll15aNHPmzMZ9+vTpEDluyJAhO9LT08vvu+++LcHzDx8+fNuiRYsa5OXl1T5YDT/+8Y/bRALvli1bakUejxo1qnll/YPTLbp27bo/mGdkZFRcf/312x599NFTKzt29OjRW2bOnNm4sLDwsDMvF+4BAAAkqc2bN6fOnz//5FWrVtXLzs7Wvn37zMx88uTJGyrr/+mnn9Y/7bTT9kjS9OnTM9asWVM3Mi94165dqdOnT2907733bpWkrl27lnbt2rXg3nvvLWjcuPFZmzdvTm3evPk+KTRqnJJyYO6sVauWsrOzN48dO7bSwBt+3v1TNFq2bNk9Ly9v+dH8GzzwwAPf9uzZs8tNN920NbivSZMm+6699trCxx9/vNIQfSiMJAMAACSp6dOnNxo4cOC2jRs35uTn5+ds3rx5aatWrcreeeedBsG+K1eurD169OhWw4cP37Jv3z7NnTs3Y/Hixbn5+fk5+fn5OS+99NLqWbNmZUjSyy+/fEpFRYUkKScnp25qaqo3adJkXyw1ZWdnb5s3b97JhYWF1TIY26xZs339+/ff/r//+79NKtv/4IMPfjtt2rSm+/bts8M5LyPJAAAAcRLrkm3xMmvWrMb333//pui2a665Zvv06dMzxowZs3n9+vV1Onfu3CWyBNzw4cO3jBw5ctvcuXPTmzVrVtauXbu9keOuvPLK4ltvvbXdunXrar344ouNR48e3bpu3boVaWlpPnXq1K/T0mKLjXXr1vWsrKwtv/rVr1rH4zVG5iRHtkeNGrXppz/96fboPg8++ODmadOmNa3s+BYtWpRfeeWV2//whz8c1txkQjIAAECSWrBgwcpg20MPPbR/rnBJScmiyo7r169fcb9+/fKi29LS0lRQULBUkubOnbvmUM+bn5+fE709YsSIbZL2r7/80EMPbYmuI9bzVFZncXHxPyrbF73mcevWrcv37Nmzf/vJJ5/cGN136tSpG6ZOnVrpFJSDYboFAAAAEBBTSDazK8xspZmtNrPRlew3M5sQ3r/UzHrGv1QAAACgelQZks0sVdIkSVdK6iJpsJl1CXS7UlL78E+WpMlxrhMAAKAmqqioqDisC8JQc4Tfu4rK9sUyktxb0mp3X+PuZZJelnRNoM81kl7wkPmSGppZXBeSBgAAqIGWFRQUnEJQTj4VFRVWUFBwiqRlle236EWlK+1gdp2kK9z9tvD2jyWd6+7ZUX3mSnrU3eeFt9+XNMrdFwbOlaXQSLMkdZR0wGTz40gTSQes14ekwfuXvHjvkhvvX/I63t+777r7AasnfPHFF6empaVNldRNXOuVbCokLSsvL7+tV69eB1xkGMvqFpV9Mgom61j6yN2fk/RcDM+Z9MxsobtnJroOHBnev+TFe5fceP+S14n63oXD1dWJrgPxF8snng2Sote5ayVp4xH0AQAAAJJCLCH5c0ntzaydmdWWdJOk2YE+syUNC69y8T1JO9x9U/BEAAAAQDKocrqFu5ebWbaktyWlSvqju+ea2e3h/VMkvSXpKkmrJe2W9NNjV3LSOCGmlRzHeP+SF+9dcuP9S168dziuVHnhHgAAAHCi4SpMAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQQEiOEzPrZ2b8ewIATghmVtfMDrgDnZmdamZ1E1ETEE+Euvi5SdKXZvY7M+uc6GJw+MzsfDN718xWmdkaM/vazNYkui4cnJkVm1lRJT/FZlaU6PoQGzPrYGbvm9my8PaZZvZQoutClSZIuqCS9r6Sfl/NtQBxxxJwcWRmJ0sarNA60S7pT5JecvfihBaGmJhZnqR7JH0haV+k3d23Jawo4ARgZh9J+oWkZ9397HDbMnfvltjKcChmttzduxxkX667d63umoB4qvJmIoiduxeZ2auS6km6W9K1kn5hZhPcfWJCi0Msdrj7XxJdBGJnZhmH2u/uhdVVC45KfXdfYGbRbeWJKgYxs0Ps45tqJD1CcpyYWX9Jt0o6XdJ0Sb3dfYuZ1Ze0QhIhueb70Mwek/SapNJIo7svSlxJqMIXCn1rU9kfa5d0WvWWgyO01cxOV+g9k5ldJ2lTYktCDLaYWW93XxDdaGbnSCpIUE1A3DDdIk7M7AVJU93940r2XeLu7yegLBwGM/uwkmZ394urvRjgBGJmpyl0S+PzJG2X9LWkoe6+LqGF4ZDMrLekmZL+R6EPrJKUKWmYpJvc/bMElQbEBSE5TsysnaRN7l4S3q4nqZm7r01oYcAJwswaSWovaf9V9ZV9aEXNYmapkh5191+Y2UmSUriOI3mYWTNJd0iKzB/PlfS0u29JXFVAfBCS48TMFko6z93Lwtu1Jf0/dz8nsZUhVmZ2iqSHJV0YbvpI0lh335G4qhALM7tN0khJrST9Q9L3JH3KtwDJwcw+4L0CUNMwJzl+0iIBWZLcvSwclJE8/ihpmaQbwts/VmiFkoEJqwixGinpHEnz3f0iM+sk6TcJrgmxW2xmsyXNkrQr0ujuryWuJFTFzHIUnkce5pK2SvpQ0uORb1aBZEVIjp8CM7va3WdLkpldo9AvCySP0919UNT2b8zsH4kqBoelxN1LzExmVsfd88ysY6KLQswyJG2TFD2a7ApdRIuaq18lbRmSblHoYvX/qN5ygPgiJMfP7ZJmmNnTCl1pv16hixeQPPaY2Q/cfZ4UurmIpD0Jrgmx2WBmDSW9LuldM9suaWNCK0LM3P2nia4Bh+8gF1auU+ibgcXVXQ8Qb8xJjjMza6DQvysXniQZMztL0jRJpyj0QadQ0k/cfUki68LhMbMfKvQe/jV6ChRqLjNrpdDI4/kKjSDPkzTS3TcktDAcMTNb4u49El0HcDQIyXFkZj+S1FX/fnX92MRVhCMRvnOi3J3bGicJM/uepNzIh1MzS5fUhSWokoOZvSvpfxVaY16SblZoCbi+iasKVTGznpU0N1Lo/dvp7ndVc0lAXBGS48TMpkiqL+kiSVMlXSdpgbv/LKGFoUpmdrO7v2hm91a2392frO6acHjCX+329PAvNDNLkbTQ3Sv7I44axsz+4e5nVdWGmqWSteVdobnlf5P0nLvvrfaigDhiTnL8nOfuZ5rZUnf/jZk9IS46SRYnhf+bntAqcDTMoz7xu3uFmfH7LXlsNbObJb0U3h6sUNhCDebuFx1sX3j95G+rsRwg7vgjEj+RpW52m9l3FPoF3y6B9SBG7v5s+L8sGZa81pjZCEmTw9t3SFqTwHpweG6V9LSk3ys0GvlJuA1JJLzW/CBJQyR1ltQysRUBRycl0QUcR+aEr65/TNIiSWv1r1ERJAEz+52ZnWxmtczsfTOLjG6h5rtdoVsa50vaIOlcSVkJrQgxc/dv3P1qd2/q7qe6+wBuSZ0czKyemd1oZm8otM78k5J+K6l1YisDjh5zkuMgPP/xe+7+SXi7jqS63KktuUTmQJrZtZIGSLpH0odcoQ0cW2Y2TaHVLP4Z3m4k6Ql3ZzS5BjOzGQrdofQdSS9L+kDSanfnW1QcFxhJjgN3r5D0RNR2KQE5KdUK//cqSS+5e2Eii0HszKxDePR/WXj7TDN7KNF1IWZnRgKyJLn7dklnJ64cxKibpO2SVkjKc/d9+vc78AFJjZAcP++Y2SAzs0QXgiM2x8zyJGVKet/Mmupfc81Rsz0v6QFJeyXJ3ZdKuimhFeFwpIRHjyVJZpYhrpmp8cLfst0g6WRJ75nZ3yWlm1nzxFYGxAfTLeLEzIoVWiWhXKFgZZLc3U9OaGE4LOE/1EXuvs/M6ks62d03J7ouHJqZfe7u55jZYnc/O9zGEmJJwsyGKfQh5/+Gm66X9F/uPv3gR6GmMbNMhVYmuV7SBnc/L8ElAUeFT+px4u4sH5akzOxid//AzAZGtUV3YSm/mm+rmZ2u8Fe9ZnadpE2JLQmxcvcXzGyhpIvDTQPdfXkia8Lhc/eFkhaa2c8VmqssSTKzB9z9vxNXGXBkCMlxYmYXVtbu7h9Xdy04bD9U6IKT/pXscxGSk8Gdkp6T1MnM8iV9LWloYktCVcLf1ux1973uvtzM9il0TUAnSYTkJBVes/yjqKbrJRGSkXSYbhEnZjYnarOupN6SvnD3iw9yCIA4M7OTFLrWYo+kG919RoJLwiGY2ceSfubuX5rZGZIWSJohqYukz919dEILRFxET4MCkgkX7sWJu/eP+umr0FW/3G0oiZjZI+G1riPbjczstwksCVUIr2v9gJk9bWZ9Je2WdIuk1QpdUISarZG7fxl+fItCq8rcJelKST9KXFmIM0bjkJQIycfOBoWCMpLHlZUsQ3VV4spBDKZL6igpR9J/KLRe6/WSBrj7NYksDDGJDk8XS3pXkty9TFJFQirCscCqT0hKzEmOEzObqH/9wk+RdJakJQkrCEci1czquHupFLqTlKQ6Ca4Jh3aau3eXJDObKmmrpDbuXpzYshCjpWb2uEJ3SjxDoQ85iv5GB8eFWYkuADgShOT4WRj1uFyhrw3/X6KKwRF5UaH1kf+k0AeeWyVNS2xJqMLeyIPwsn1fE5CTyn9IGimpraTL3H13uL2LpMcTVRRiY2a/k7TG3acE2u+R1NzdR0mSuz+SiPqAo8WFe3ESvmCoJHzHIZlZqqQ6Ub/0kQTM7ApJlyr09eA77v52gkvCIYRXQ9gV2ZRUT6F5yaxTnqTMrKe7L0p0HaiamS2X1C1819no9hRJS92dKYdIaowkx8/7CoWrneHtegp9dchi6sllhaRyd3/PzOqbWTojkzWXu6cmugbE3VRJPRNdBGLiwYAcbqzg7rM4HnDhXvzUdfdIQFb4cf0E1oPDZGb/odAdv54NN7WU9HrCCgJOTISr5LHbzNoHG8NtexJQDxBXhOT42WVm+0c/zKyX+CWRbO6UdL6kIkkKL011akIrAk48v0l0AYjZGEl/MbOfmFn38M9PJb0Z3gckNaZbxM/dkmaZ2cbwdgtJNyauHByBUncvi3xLaGZpYn1PoFq5++uSZGad3D0vweXgENz9L2Y2QNIvJN0Vbs6VNMjdcxJWGBAnXLgXR2ZWS6E1W01SnrvvreIQ1CDhK7X/KWmYQr/w75C03N0fTGRdwInIzL5x9zaJrgOxMbMGCs1R3lVlZyBJEJLjxMzulDQjcjMKM2skabC7P5PQwhCz8IUmt0m6TKEPOm9Lmur8TwIcE2Y24WC7JN3C6iQ1n5ndIWm0pJPCTTsljeNvH44HhOQ4MbN/uPtZgTbuV58kWLIIqH5mVizpPkmllex+wt2bVHNJOAxm9pBCKzhlu/uacNtpksZL+szdf5vI+oCjxZzk+EkxM4uMOobXSa6d4JoQo/CSRUvMrI27f5PoeoATxOeSlrn7J8EdZvbr6i8Hh+nHknq4e0mkwd3XmNkNCt1xlpCMpEZIjp+3Jc00sykKXex1u6S/JLYkHKYWknLNbIH+dYMKufvViSsJOK5dJ6mksh3u3q6aa8ERiA7IUW17zOyA9ZOBZENIjp9RkrIk/R+F5tMtVih0IXmw9BRQvRq4e2Gii8AR22Bml7j7+9GNZnaxpE0JqgmIG0JynIS/rp8v6TSFln7LkPRqYqtCLMysrkIj/2dIypH0B3cvT2xVwAnhdYXvrmdmr7r7oMSWg8M0QtIbZjZP0hcKfYt6jkLrzV+TyMKAeCAkHyUz6yDpJkmDJW2T9IokuftFiawLh2WapL2S/i7pSkldJI1MaEXAiSH67nqnJawKHBF3zzWzbpKGSOqq0Pv5saThlU3DAJINIfno5SkUrvq7+2pJMrN7ElsSDlMXd+8uSWb2B0kLElwPcKLwgzxGkgiH4T9Gt5lZqpkNdfcZCSoLiAtuS330BknaLOlDM3vezC7Rv4+OoObbf9MXplkA1aqHmRWFl4I7M/y4yMyKzawo0cXh0MzsZDN7wMyeNrO+FpItaY2kGxJdH3C0WCc5TszsJEkDFJp2cbFCX+H/2d3fSWRdqJqZ7dO/VrMwSfUk7Q4/dm5oAAAHMrM3JG2X9KmkSyQ1Umjp05Hu/o8ElgbEBSH5GDCzDEnXS7rR3S9OdD0AAMSbmeVETVVLlbRVUht3L05sZUB8EJIBAMBhM7NF7t7zYNtAsiMkAwCAw8ZUNRzvCMkAAABAAKtbAAAAAAGEZAAAACCAkAygRjOzB80s18yWmtk/zOzcRNcEADj+ccc9ADWWmX1fUj9JPd291MyaKLQO65GeL40bxgAAYsFIMoCarIWkre5eKknuvtXdN5rZOWb2iZktMbMFZpZuZnXN7E9mlmNmi83sIkkys5+Y2SwzmyPpHTM7ycz+aGafh/tdk8gXCAComRhJBlCTvSNpjJmtkvSepFcUurvXKwrdrOdzMztZ0h5JIyXJ3bubWSeFAnGH8Hm+L+lMdy80s0ckfeDut5pZQ0kLzOw9d98lAADCGEkGUGO5+05JvSRlSSpQKBwPl7TJ3T8P9ykKT6H4gaTp4bY8SeskRULyu+5eGH58maTRZvYPSX+TVFdSm+p4PQCA5MFIMoAazd33KRRm/2ZmOZLulFTZAu92iNNEjxKbpEHuvjJuRQIAjjuMJAOoscyso5m1j2o6S9IKSd8xs3PCfdLNLE3Sx5KGhts6KDQ6XFkQflvSXWZm4b5nH7tXAABIVowkA6jJGkiaGJ47XC5ptUJTL/4Ubq+n0HzkSyU9I2lKeLS5XNJPwitiBM/5n5KekrQ0HJTXKrSCBgAA+3FbagAAACCA6RYAAABAACEZAAAACCAkAwAAAAGEZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEPD/AeF8Et10hBfmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation.plot(y=X_samples.keys(), kind=\"bar\", figsize=(10, 5))\n",
    "plt.legend(loc=(1.01, 0.))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
