{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "occupational-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "monthly-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-edinburgh",
   "metadata": {},
   "source": [
    "# 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subject-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./datasets/X_samples.pickle\", \"rb\") as f:\n",
    "    X_samples = pickle.load(f)\n",
    "    \n",
    "with open(f\"./datasets/y_samples.pickle\", \"rb\") as f:\n",
    "    y_samples = pickle.load(f)\n",
    "    \n",
    "with open(f\"./datasets/X_test.pickle\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "    \n",
    "with open(f\"./datasets/y_test.pickle\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cellular-carry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201810</th>\n",
       "      <td>0.579847</td>\n",
       "      <td>-0.011862</td>\n",
       "      <td>1.035499</td>\n",
       "      <td>-0.317540</td>\n",
       "      <td>0.216728</td>\n",
       "      <td>1.201270</td>\n",
       "      <td>-0.537323</td>\n",
       "      <td>1.319719</td>\n",
       "      <td>-0.189181</td>\n",
       "      <td>-0.627079</td>\n",
       "      <td>-0.131042</td>\n",
       "      <td>0.186976</td>\n",
       "      <td>0.428736</td>\n",
       "      <td>-0.650821</td>\n",
       "      <td>0.607427</td>\n",
       "      <td>-1.605008</td>\n",
       "      <td>-0.426110</td>\n",
       "      <td>-0.604022</td>\n",
       "      <td>0.099792</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.286629</td>\n",
       "      <td>0.166828</td>\n",
       "      <td>0.550873</td>\n",
       "      <td>-0.323683</td>\n",
       "      <td>-0.402491</td>\n",
       "      <td>0.195611</td>\n",
       "      <td>-0.573086</td>\n",
       "      <td>-0.079200</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>-0.254035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264506</th>\n",
       "      <td>0.901937</td>\n",
       "      <td>2.267601</td>\n",
       "      <td>-1.634754</td>\n",
       "      <td>-2.368609</td>\n",
       "      <td>-2.592182</td>\n",
       "      <td>1.161092</td>\n",
       "      <td>3.434814</td>\n",
       "      <td>-1.615728</td>\n",
       "      <td>0.797080</td>\n",
       "      <td>-1.404452</td>\n",
       "      <td>1.591339</td>\n",
       "      <td>-0.219360</td>\n",
       "      <td>-0.722225</td>\n",
       "      <td>0.316331</td>\n",
       "      <td>-0.203926</td>\n",
       "      <td>0.188359</td>\n",
       "      <td>-0.707386</td>\n",
       "      <td>0.435844</td>\n",
       "      <td>-0.286008</td>\n",
       "      <td>-0.261407</td>\n",
       "      <td>-0.343678</td>\n",
       "      <td>-0.163936</td>\n",
       "      <td>-0.078568</td>\n",
       "      <td>0.259323</td>\n",
       "      <td>0.687408</td>\n",
       "      <td>-0.131926</td>\n",
       "      <td>-0.141368</td>\n",
       "      <td>0.026772</td>\n",
       "      <td>-0.055990</td>\n",
       "      <td>0.041920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63736</th>\n",
       "      <td>-0.397573</td>\n",
       "      <td>1.118301</td>\n",
       "      <td>-1.260762</td>\n",
       "      <td>0.981093</td>\n",
       "      <td>-0.380698</td>\n",
       "      <td>-1.876228</td>\n",
       "      <td>-0.490142</td>\n",
       "      <td>-1.089500</td>\n",
       "      <td>0.062601</td>\n",
       "      <td>0.119233</td>\n",
       "      <td>0.495179</td>\n",
       "      <td>-0.818852</td>\n",
       "      <td>-1.269072</td>\n",
       "      <td>-1.259742</td>\n",
       "      <td>-0.383677</td>\n",
       "      <td>0.541024</td>\n",
       "      <td>1.271092</td>\n",
       "      <td>0.402624</td>\n",
       "      <td>-0.814504</td>\n",
       "      <td>0.430227</td>\n",
       "      <td>0.227343</td>\n",
       "      <td>0.364685</td>\n",
       "      <td>0.773901</td>\n",
       "      <td>-0.193256</td>\n",
       "      <td>0.415118</td>\n",
       "      <td>0.360261</td>\n",
       "      <td>-0.054869</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>0.043857</td>\n",
       "      <td>1.553832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241327</th>\n",
       "      <td>0.778757</td>\n",
       "      <td>2.063018</td>\n",
       "      <td>0.608260</td>\n",
       "      <td>-3.168853</td>\n",
       "      <td>0.618313</td>\n",
       "      <td>1.228515</td>\n",
       "      <td>-1.367266</td>\n",
       "      <td>0.683151</td>\n",
       "      <td>-0.308130</td>\n",
       "      <td>-0.147176</td>\n",
       "      <td>-0.859443</td>\n",
       "      <td>1.672501</td>\n",
       "      <td>0.060919</td>\n",
       "      <td>-0.917332</td>\n",
       "      <td>-2.099999</td>\n",
       "      <td>-0.637629</td>\n",
       "      <td>0.540038</td>\n",
       "      <td>1.976581</td>\n",
       "      <td>1.105321</td>\n",
       "      <td>-0.025014</td>\n",
       "      <td>-0.155587</td>\n",
       "      <td>-0.022321</td>\n",
       "      <td>0.076885</td>\n",
       "      <td>-0.042470</td>\n",
       "      <td>0.578092</td>\n",
       "      <td>0.345450</td>\n",
       "      <td>0.660782</td>\n",
       "      <td>-0.089294</td>\n",
       "      <td>-0.023863</td>\n",
       "      <td>-0.296793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271841</th>\n",
       "      <td>0.940836</td>\n",
       "      <td>-1.212528</td>\n",
       "      <td>0.730185</td>\n",
       "      <td>1.549615</td>\n",
       "      <td>-0.954037</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>-0.092019</td>\n",
       "      <td>0.124386</td>\n",
       "      <td>0.595537</td>\n",
       "      <td>-0.570630</td>\n",
       "      <td>-1.090583</td>\n",
       "      <td>0.339272</td>\n",
       "      <td>0.843626</td>\n",
       "      <td>0.394601</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>-0.512564</td>\n",
       "      <td>0.792514</td>\n",
       "      <td>-0.751414</td>\n",
       "      <td>0.277571</td>\n",
       "      <td>0.372448</td>\n",
       "      <td>-0.012042</td>\n",
       "      <td>-0.161695</td>\n",
       "      <td>-0.744489</td>\n",
       "      <td>-0.173554</td>\n",
       "      <td>-0.405409</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>-0.143519</td>\n",
       "      <td>-0.050795</td>\n",
       "      <td>0.034654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "201810  0.579847 -0.011862  1.035499 -0.317540  0.216728  1.201270 -0.537323   \n",
       "264506  0.901937  2.267601 -1.634754 -2.368609 -2.592182  1.161092  3.434814   \n",
       "63736  -0.397573  1.118301 -1.260762  0.981093 -0.380698 -1.876228 -0.490142   \n",
       "241327  0.778757  2.063018  0.608260 -3.168853  0.618313  1.228515 -1.367266   \n",
       "271841  0.940836 -1.212528  0.730185  1.549615 -0.954037  0.008643 -0.092019   \n",
       "\n",
       "              V7        V8        V9       V10       V11       V12       V13  \\\n",
       "201810  1.319719 -0.189181 -0.627079 -0.131042  0.186976  0.428736 -0.650821   \n",
       "264506 -1.615728  0.797080 -1.404452  1.591339 -0.219360 -0.722225  0.316331   \n",
       "63736  -1.089500  0.062601  0.119233  0.495179 -0.818852 -1.269072 -1.259742   \n",
       "241327  0.683151 -0.308130 -0.147176 -0.859443  1.672501  0.060919 -0.917332   \n",
       "271841  0.124386  0.595537 -0.570630 -1.090583  0.339272  0.843626  0.394601   \n",
       "\n",
       "             V14       V15       V16       V17       V18       V19       V20  \\\n",
       "201810  0.607427 -1.605008 -0.426110 -0.604022  0.099792  0.000011 -0.286629   \n",
       "264506 -0.203926  0.188359 -0.707386  0.435844 -0.286008 -0.261407 -0.343678   \n",
       "63736  -0.383677  0.541024  1.271092  0.402624 -0.814504  0.430227  0.227343   \n",
       "241327 -2.099999 -0.637629  0.540038  1.976581  1.105321 -0.025014 -0.155587   \n",
       "271841  0.266667 -0.512564  0.792514 -0.751414  0.277571  0.372448 -0.012042   \n",
       "\n",
       "             V21       V22       V23       V24       V25       V26       V27  \\\n",
       "201810  0.166828  0.550873 -0.323683 -0.402491  0.195611 -0.573086 -0.079200   \n",
       "264506 -0.163936 -0.078568  0.259323  0.687408 -0.131926 -0.141368  0.026772   \n",
       "63736   0.364685  0.773901 -0.193256  0.415118  0.360261 -0.054869  0.016690   \n",
       "241327 -0.022321  0.076885 -0.042470  0.578092  0.345450  0.660782 -0.089294   \n",
       "271841 -0.161695 -0.744489 -0.173554 -0.405409  0.217600  0.357895 -0.143519   \n",
       "\n",
       "             V28    Amount  \n",
       "201810  0.015847 -0.254035  \n",
       "264506 -0.055990  0.041920  \n",
       "63736   0.043857  1.553832  \n",
       "241327 -0.023863 -0.296793  \n",
       "271841 -0.050795  0.034654  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "external-mistake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201810    0\n",
       "264506    0\n",
       "63736     0\n",
       "241327    0\n",
       "271841    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "racial-turkish",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Raw\n",
      "====================================================================================================\n",
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "143144  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "258914  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "51111  -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "146949  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "135606 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "              V7        V8        V9       V10       V11       V12       V13  \\\n",
      "143144  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "258914 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "51111  -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "146949  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "135606  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "             V14       V15       V16       V17       V18       V19       V20  \\\n",
      "143144 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "258914 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "51111  -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "146949  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "135606 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "             V21       V22       V23       V24       V25       V26       V27  \\\n",
      "143144 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "258914 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "51111   0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "146949 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "135606 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "             V28    Amount  \n",
      "143144 -0.093342 -0.296793  \n",
      "258914 -0.041962  0.565919  \n",
      "51111   0.240607 -0.296793  \n",
      "146949  0.223898 -0.237546  \n",
      "135606  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0    227447\n",
      "1       398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 227845\n",
      "0 비율 :  99.83 %\n",
      "1 비율 :   0.17 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "SMOTE\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "1  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "2 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "3  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "1 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "2 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "3  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "1 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "2 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "3  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "1 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "2  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "3 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0 -0.093342 -0.296793  \n",
      "1 -0.041962  0.565919  \n",
      "2  0.240607 -0.296793  \n",
      "3  0.223898 -0.237546  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0    227447\n",
      "1    227447\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 454894\n",
      "0 비율 :  50.00 %\n",
      "1 비율 :  50.00 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "ADASYN\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "1  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "2 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "3  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "1 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "2 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "3  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "1 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "2 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "3  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "1 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "2  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "3 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0 -0.093342 -0.296793  \n",
      "1 -0.041962  0.565919  \n",
      "2  0.240607 -0.296793  \n",
      "3  0.223898 -0.237546  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    227453\n",
      "0    227447\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 454900\n",
      "1 비율 :  50.00 %\n",
      "0 비율 :  50.00 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "CNN\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.989403 -0.147206  1.099073 -0.448814 -0.670465  0.813368 -0.624680   \n",
      "1  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "2  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "3 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.824100  0.068627 -0.036771 -0.339651  1.049736  0.317577 -0.675746   \n",
      "1  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "2 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "3 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -0.768674 -0.869056  0.497980  0.186416  0.290770 -0.013677  0.109644   \n",
      "1 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "2 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "3 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.320720 -0.768440  0.111616  0.642187 -0.437602  0.093575  0.327780   \n",
      "1 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "2 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "3  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0  0.130896 -0.211835  \n",
      "1 -0.093342 -0.296793  \n",
      "2 -0.041962  0.565919  \n",
      "3  0.240607 -0.296793  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0    908\n",
      "1    398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 1306\n",
      "0 비율 :  69.53 %\n",
      "1 비율 :  30.47 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "SMOTE + ENN\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "1  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "2 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "3  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "1 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "2 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "3  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "1 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "2 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "3  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "1 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "2  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "3 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0 -0.093342 -0.296793  \n",
      "1 -0.041962  0.565919  \n",
      "2  0.240607 -0.296793  \n",
      "3  0.223898 -0.237546  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    227447\n",
      "0    227056\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 454503\n",
      "1 비율 :  50.04 %\n",
      "0 비율 :  49.96 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "ADASYN + ENN\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "1  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "2 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "3  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "1 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "2 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "3  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "1 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "2 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "3  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "1 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "2  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "3 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0 -0.093342 -0.296793  \n",
      "1 -0.041962  0.565919  \n",
      "2  0.240607 -0.296793  \n",
      "3  0.223898 -0.237546  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    227453\n",
      "0    227056\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 454509\n",
      "1 비율 :  50.04 %\n",
      "0 비율 :  49.96 %\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for key, sample in X_samples.items():\n",
    "    y = y_samples[key]\n",
    "    total = len(y)\n",
    "    counts = y.value_counts()\n",
    "    \n",
    "    print('=' * 100)\n",
    "    print(key)\n",
    "    print('=' * 100)\n",
    "    print(sample.head())\n",
    "    print('-' * 100)\n",
    "    print(counts)\n",
    "    print('-' * 30)\n",
    "    print(f\"Total : {total}\")\n",
    "    for idx in counts.index:\n",
    "        print(f\"{idx} 비율 : {counts[idx] / total * 100:6.2f} %\")\n",
    "    print('=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-electron",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quantitative-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data_info(y):\n",
    "    total = len(y)\n",
    "    counts = y.value_counts()\n",
    "    print('=' * 80)\n",
    "    print(counts)\n",
    "    print('-' * 30)\n",
    "    for idx in counts.index:\n",
    "        print(f\"{idx} 비율 : {counts[idx] / total * 100:6.2f} %\")\n",
    "    print('=' * 80)\n",
    "\n",
    "def evaluate_model(clf, x_test, y_test):\n",
    "    y_proba = clf.predict_proba(x_test)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    fl = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "    \n",
    "    print('=' * 80)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('-' * 60)\n",
    "    print(f'Accuracy  : {accuracy}')\n",
    "    print(f'Precision : {precision}')\n",
    "    print(f'Recall    : {recall}')\n",
    "    print(f'F1-Score  : {fl}')\n",
    "    print('-' * 60)\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print('-' * 60)\n",
    "    print(f'ROC AUC : {roc_auc}')\n",
    "    print('=' * 80)\n",
    "    \n",
    "    return accuracy, precision, recall, fl, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recreational-absolute",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Raw\n",
      "================================================================================\n",
      "0    227447\n",
      "1       398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  99.83 %\n",
      "1 비율 :   0.17 %\n",
      "================================================================================\n",
      "CatBoost Raw\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56865     3]\n",
      " [   24    70]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995259997893332\n",
      "Precision : 0.958904109589041\n",
      "Recall    : 0.7446808510638298\n",
      "F1-Score  : 0.8383233532934131\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.96      0.74      0.84        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.98      0.87      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9757617117056447\n",
      "================================================================================\n",
      "================================================================================\n",
      "SMOTE\n",
      "================================================================================\n",
      "0    227447\n",
      "1    227447\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  50.00 %\n",
      "1 비율 :  50.00 %\n",
      "================================================================================\n",
      "CatBoost SMOTE\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56790    78]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9983322214809873\n",
      "Precision : 0.4967741935483871\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.6184738955823293\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.50      0.82      0.62        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.75      0.91      0.81     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9760303442537328\n",
      "================================================================================\n",
      "================================================================================\n",
      "ADASYN\n",
      "================================================================================\n",
      "1    227453\n",
      "0    227447\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "1 비율 :  50.00 %\n",
      "0 비율 :  50.00 %\n",
      "================================================================================\n",
      "CatBoost ADASYN\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56791    77]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9983497770443454\n",
      "Precision : 0.5\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.6209677419354839\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.50      0.82      0.62        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.75      0.91      0.81     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9758747019974588\n",
      "================================================================================\n",
      "================================================================================\n",
      "CNN\n",
      "================================================================================\n",
      "0    908\n",
      "1    398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  69.53 %\n",
      "1 비율 :  30.47 %\n",
      "================================================================================\n",
      "CatBoost CNN\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56860     8]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995435553526912\n",
      "Precision : 0.9047619047619048\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.853932584269663\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.90      0.81      0.85        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.95      0.90      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9759227789924858\n",
      "================================================================================\n",
      "================================================================================\n",
      "SMOTE + ENN\n",
      "================================================================================\n",
      "1    227447\n",
      "0    227056\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "1 비율 :  50.04 %\n",
      "0 비율 :  49.96 %\n",
      "================================================================================\n",
      "CatBoost SMOTE + ENN\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56806    62]\n",
      " [   16    78]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9986306660580738\n",
      "Precision : 0.5571428571428572\n",
      "Recall    : 0.8297872340425532\n",
      "F1-Score  : 0.6666666666666667\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.56      0.83      0.67        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.78      0.91      0.83     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9794483005811143\n",
      "================================================================================\n",
      "================================================================================\n",
      "ADASYN + ENN\n",
      "================================================================================\n",
      "1    227453\n",
      "0    227056\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "1 비율 :  50.04 %\n",
      "0 비율 :  49.96 %\n",
      "================================================================================\n",
      "CatBoost ADASYN + ENN\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56786    82]\n",
      " [   15    79]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9982971103542713\n",
      "Precision : 0.4906832298136646\n",
      "Recall    : 0.8404255319148937\n",
      "F1-Score  : 0.6196078431372549\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.49      0.84      0.62        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.75      0.92      0.81     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.978338227085045\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "clfs, results = {}, {}\n",
    "\n",
    "for key, X in X_samples.items():\n",
    "    y = y_samples[key]\n",
    "    \n",
    "    print('=' * 80)\n",
    "    print(key)\n",
    "    show_data_info(y)\n",
    "    \n",
    "    clf = CatBoostClassifier(eval_metric='F1', early_stopping_rounds=100, verbose=False)\n",
    "    clf.fit(X, y, eval_set=(X_test, y_test))\n",
    "    \n",
    "    print(f'CatBoost {key}')\n",
    "    result = evaluate_model(clf, X_test, y_test)\n",
    "    \n",
    "    clfs[key] = clf\n",
    "    results[key] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "received-subdivision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Raw\n",
      "================================================================================\n",
      "0    227447\n",
      "1       398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  99.83 %\n",
      "1 비율 :   0.17 %\n",
      "================================================================================\n",
      "CatBoost Balanced\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[54869  1999]\n",
      " [   10    84]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9647308732137214\n",
      "Precision : 0.040326452232357174\n",
      "Recall    : 0.8936170212765957\n",
      "F1-Score  : 0.07717041800643086\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56868\n",
      "           1       0.04      0.89      0.08        94\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.93      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9736473528095672\n",
      "================================================================================\n",
      "================================================================================\n",
      "Raw\n",
      "================================================================================\n",
      "0    227447\n",
      "1       398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  99.83 %\n",
      "1 비율 :   0.17 %\n",
      "================================================================================\n",
      "CatBoost SqrtBalanced\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56857    11]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995084442259752\n",
      "Precision : 0.875\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.8461538461538463\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.88      0.82      0.85        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.94      0.91      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9835578547708093\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "class_weights = ['Balanced', 'SqrtBalanced']\n",
    "\n",
    "for class_weight in class_weights:\n",
    "    X, y = X_samples['Raw'], y_samples['Raw']\n",
    "    \n",
    "    print('=' * 80)\n",
    "    print('Raw')\n",
    "    show_data_info(y)\n",
    "    \n",
    "    clf = CatBoostClassifier(eval_metric='F1', auto_class_weights=class_weight,\n",
    "                             early_stopping_rounds=100, verbose=False)\n",
    "    clf.fit(X, y, eval_set=(X_test, y_test))\n",
    "    \n",
    "    print(f'CatBoost {class_weight}')\n",
    "    result = evaluate_model(clf, X_test, y_test)\n",
    "    \n",
    "    clfs[class_weight] = clf\n",
    "    results[class_weight] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "perfect-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw</th>\n",
       "      <th>SMOTE</th>\n",
       "      <th>ADASYN</th>\n",
       "      <th>CNN</th>\n",
       "      <th>SMOTE + ENN</th>\n",
       "      <th>ADASYN + ENN</th>\n",
       "      <th>Balanced</th>\n",
       "      <th>SqrtBalanced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.998332</td>\n",
       "      <td>0.998350</td>\n",
       "      <td>0.999544</td>\n",
       "      <td>0.998631</td>\n",
       "      <td>0.998297</td>\n",
       "      <td>0.964731</td>\n",
       "      <td>0.999508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.496774</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.490683</td>\n",
       "      <td>0.040326</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.819149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.618474</td>\n",
       "      <td>0.620968</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.077170</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC_AUC</th>\n",
       "      <td>0.975762</td>\n",
       "      <td>0.976030</td>\n",
       "      <td>0.975875</td>\n",
       "      <td>0.975923</td>\n",
       "      <td>0.979448</td>\n",
       "      <td>0.978338</td>\n",
       "      <td>0.973647</td>\n",
       "      <td>0.983558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Raw     SMOTE    ADASYN       CNN  SMOTE + ENN  ADASYN + ENN  \\\n",
       "Accuracy   0.999526  0.998332  0.998350  0.999544     0.998631      0.998297   \n",
       "Precision  0.958904  0.496774  0.500000  0.904762     0.557143      0.490683   \n",
       "Recall     0.744681  0.819149  0.819149  0.808511     0.829787      0.840426   \n",
       "F1-Score   0.838323  0.618474  0.620968  0.853933     0.666667      0.619608   \n",
       "ROC_AUC    0.975762  0.976030  0.975875  0.975923     0.979448      0.978338   \n",
       "\n",
       "           Balanced  SqrtBalanced  \n",
       "Accuracy   0.964731      0.999508  \n",
       "Precision  0.040326      0.875000  \n",
       "Recall     0.893617      0.819149  \n",
       "F1-Score   0.077170      0.846154  \n",
       "ROC_AUC    0.973647      0.983558  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC_AUC']\n",
    "    \n",
    "evaluation = pd.DataFrame(results, index=cols)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "offensive-airline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation.plot(kind=\"bar\", figsize=(10, 5), rot=0)\n",
    "plt.legend(loc=(1.01, 0.))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-reliance",
   "metadata": {},
   "source": [
    "## 가중치 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "differential-formula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    227447\n",
       "1       398\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = y_samples['Raw'].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "associate-mattress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571.4748743718593\n",
      "23.90554066261333\n"
     ]
    }
   ],
   "source": [
    "print(counts[0] / counts[1])\n",
    "print(np.sqrt(counts[0] / counts[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prerequisite-inspection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  2.63333333,  4.26666667,  5.9       ,  7.53333333,\n",
       "        9.16666667, 10.8       , 12.43333333, 14.06666667, 15.7       ,\n",
       "       17.33333333, 18.96666667, 20.6       , 22.23333333, 23.86666667,\n",
       "       25.5       , 27.13333333, 28.76666667, 30.4       , 32.03333333,\n",
       "       33.66666667, 35.3       , 36.93333333, 38.56666667, 40.2       ,\n",
       "       41.83333333, 43.46666667, 45.1       , 46.73333333, 48.36666667])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.linspace(1.0, 50.0, 30, endpoint=False)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "technological-expense",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Weight 1.0\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56865     3]\n",
      " [   24    70]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995259997893332\n",
      "Precision : 0.958904109589041\n",
      "Recall    : 0.7446808510638298\n",
      "F1-Score  : 0.8383233532934131\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.96      0.74      0.84        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.98      0.87      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9757617117056447\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 2.6333333333333333\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56864     4]\n",
      " [   21    73]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995611109160493\n",
      "Precision : 0.948051948051948\n",
      "Recall    : 0.776595744680851\n",
      "F1-Score  : 0.8538011695906432\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.95      0.78      0.85        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.89      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9825497344354003\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 4.266666666666667\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56864     4]\n",
      " [   20    74]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995786664794073\n",
      "Precision : 0.9487179487179487\n",
      "Recall    : 0.7872340425531915\n",
      "F1-Score  : 0.8604651162790696\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.95      0.79      0.86        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.89      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9822947579987399\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 5.9\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56858    10]\n",
      " [   19    75]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9994908886626171\n",
      "Precision : 0.8823529411764706\n",
      "Recall    : 0.7978723404255319\n",
      "F1-Score  : 0.8379888268156425\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.88      0.80      0.84        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.94      0.90      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9808193367544699\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 7.533333333333333\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56862     6]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995786664794073\n",
      "Precision : 0.926829268292683\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.8636363636363636\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.93      0.81      0.86        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.96      0.90      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9801608502856185\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 9.166666666666666\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56855    13]\n",
      " [   19    75]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9994382219725431\n",
      "Precision : 0.8522727272727273\n",
      "Recall    : 0.7978723404255319\n",
      "F1-Score  : 0.8241758241758241\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.85      0.80      0.82        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.90      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9820351048115905\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 10.8\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56854    14]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9994557775359011\n",
      "Precision : 0.8461538461538461\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.8324324324324325\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.85      0.82      0.83        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.91      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9815808988040988\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 12.433333333333334\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56862     6]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995786664794073\n",
      "Precision : 0.926829268292683\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.8636363636363636\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.93      0.81      0.86        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.96      0.90      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.982874300919337\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 14.066666666666666\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56862     6]\n",
      " [   19    75]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995611109160493\n",
      "Precision : 0.9259259259259259\n",
      "Recall    : 0.7978723404255319\n",
      "F1-Score  : 0.8571428571428572\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.93      0.80      0.86        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.96      0.90      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9761392190051168\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 15.7\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56863     5]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9996137776061234\n",
      "Precision : 0.9390243902439024\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.875\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.94      0.82      0.88        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.91      0.94     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9763360166656939\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 17.333333333333332\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56860     8]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995611109160493\n",
      "Precision : 0.9058823529411765\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.8603351955307263\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.91      0.82      0.86        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.95      0.91      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9788504247986004\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 18.966666666666665\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56860     8]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995611109160493\n",
      "Precision : 0.9058823529411765\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.8603351955307263\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.91      0.82      0.86        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.95      0.91      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9823042985697374\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 20.6\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56862     6]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995786664794073\n",
      "Precision : 0.926829268292683\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.8636363636363636\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.93      0.81      0.86        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.96      0.90      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9839250732192056\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 22.233333333333334\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56850    18]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9993679997191109\n",
      "Precision : 0.8085106382978723\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.8085106382978723\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.81      0.81      0.81        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.90      0.90      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9823813714177962\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 23.866666666666667\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56857    11]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995084442259752\n",
      "Precision : 0.875\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.8461538461538463\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.88      0.82      0.85        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.94      0.91      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9835644022214939\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 25.5\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56853    15]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9994382219725431\n",
      "Precision : 0.8369565217391305\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.8279569892473119\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.84      0.82      0.83        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.91      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9718173403432211\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 27.133333333333333\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56854    14]\n",
      " [   19    75]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.999420666409185\n",
      "Precision : 0.8426966292134831\n",
      "Recall    : 0.7978723404255319\n",
      "F1-Score  : 0.8196721311475411\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.84      0.80      0.82        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.90      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9826632859372733\n",
      "================================================================================\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight 28.766666666666666\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56846    22]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9992977774656788\n",
      "Precision : 0.7755102040816326\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.7916666666666665\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.78      0.81      0.79        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.89      0.90      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9791398221188599\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 30.4\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56854    14]\n",
      " [   16    78]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9994733330992591\n",
      "Precision : 0.8478260869565217\n",
      "Recall    : 0.8297872340425532\n",
      "F1-Score  : 0.8387096774193549\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.85      0.83      0.84        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.91      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9773851053353866\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 32.03333333333333\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56853    15]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9994382219725431\n",
      "Precision : 0.8369565217391305\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.8279569892473119\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.84      0.82      0.83        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.91      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9650923602100572\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 33.666666666666664\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56863     5]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995962220427653\n",
      "Precision : 0.9382716049382716\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.8685714285714285\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.94      0.81      0.87        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.90      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9800890153981074\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 35.3\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56858    10]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995084442259752\n",
      "Precision : 0.8837209302325582\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.8444444444444444\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.88      0.81      0.84        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.94      0.90      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9847109543713773\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 36.93333333333333\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56849    19]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9993504441557529\n",
      "Precision : 0.8\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.8042328042328043\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.80      0.81      0.80        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.90      0.90      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9721241351752996\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 38.56666666666666\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56845    23]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9992977774656788\n",
      "Precision : 0.77\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.7938144329896908\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.77      0.82      0.79        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.88      0.91      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9752211728841258\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 40.2\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56846    22]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9993153330290369\n",
      "Precision : 0.7777777777777778\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.7979274611398963\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.78      0.82      0.80        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.89      0.91      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9618942111556588\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 41.833333333333336\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56862     6]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995786664794073\n",
      "Precision : 0.926829268292683\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.8636363636363636\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.93      0.81      0.86        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.96      0.90      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9786809393608791\n",
      "================================================================================\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight 43.46666666666667\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56861     7]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995611109160493\n",
      "Precision : 0.9156626506024096\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.8587570621468926\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.92      0.81      0.86        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.96      0.90      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9723746219314904\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 45.1\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56859     9]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995259997893332\n",
      "Precision : 0.8941176470588236\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.8491620111731844\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.89      0.81      0.85        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.95      0.90      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.969241947383938\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 46.733333333333334\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56844    24]\n",
      " [   16    78]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9992977774656788\n",
      "Precision : 0.7647058823529411\n",
      "Recall    : 0.8297872340425532\n",
      "F1-Score  : 0.7959183673469387\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.76      0.83      0.80        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.88      0.91      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9683735683531404\n",
      "================================================================================\n",
      "================================================================================\n",
      "Weight 48.36666666666667\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56846    22]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9993153330290369\n",
      "Precision : 0.7777777777777778\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.7979274611398963\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.78      0.82      0.80        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.89      0.91      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9759551421058696\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "results_weight = {}\n",
    "\n",
    "for weight in weights:\n",
    "    X, y = X_samples['Raw'], y_samples['Raw']\n",
    "    \n",
    "    print('=' * 80)\n",
    "    \n",
    "    clf = CatBoostClassifier(eval_metric='F1', scale_pos_weight=weight,\n",
    "                             early_stopping_rounds=100, verbose=False)\n",
    "    clf.fit(X, y, eval_set=(X_test, y_test))\n",
    "    \n",
    "    print(f'Weight {weight}')\n",
    "    result = evaluate_model(clf, X_test, y_test)\n",
    "    \n",
    "    results_weight[weight] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "direct-nurse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.000000</th>\n",
       "      <th>2.633333</th>\n",
       "      <th>4.266667</th>\n",
       "      <th>5.900000</th>\n",
       "      <th>7.533333</th>\n",
       "      <th>9.166667</th>\n",
       "      <th>10.800000</th>\n",
       "      <th>12.433333</th>\n",
       "      <th>14.066667</th>\n",
       "      <th>15.700000</th>\n",
       "      <th>17.333333</th>\n",
       "      <th>18.966667</th>\n",
       "      <th>20.600000</th>\n",
       "      <th>22.233333</th>\n",
       "      <th>23.866667</th>\n",
       "      <th>25.500000</th>\n",
       "      <th>27.133333</th>\n",
       "      <th>28.766667</th>\n",
       "      <th>30.400000</th>\n",
       "      <th>32.033333</th>\n",
       "      <th>33.666667</th>\n",
       "      <th>35.300000</th>\n",
       "      <th>36.933333</th>\n",
       "      <th>38.566667</th>\n",
       "      <th>40.200000</th>\n",
       "      <th>41.833333</th>\n",
       "      <th>43.466667</th>\n",
       "      <th>45.100000</th>\n",
       "      <th>46.733333</th>\n",
       "      <th>48.366667</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>0.999614</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.999421</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>0.999350</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999315</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.776596</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.819149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.824176</td>\n",
       "      <td>0.832432</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.868571</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.804233</td>\n",
       "      <td>0.793814</td>\n",
       "      <td>0.797927</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.797927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC_AUC</th>\n",
       "      <td>0.975762</td>\n",
       "      <td>0.982550</td>\n",
       "      <td>0.982295</td>\n",
       "      <td>0.980819</td>\n",
       "      <td>0.980161</td>\n",
       "      <td>0.982035</td>\n",
       "      <td>0.981581</td>\n",
       "      <td>0.982874</td>\n",
       "      <td>0.976139</td>\n",
       "      <td>0.976336</td>\n",
       "      <td>0.978850</td>\n",
       "      <td>0.982304</td>\n",
       "      <td>0.983925</td>\n",
       "      <td>0.982381</td>\n",
       "      <td>0.983564</td>\n",
       "      <td>0.971817</td>\n",
       "      <td>0.982663</td>\n",
       "      <td>0.979140</td>\n",
       "      <td>0.977385</td>\n",
       "      <td>0.965092</td>\n",
       "      <td>0.980089</td>\n",
       "      <td>0.984711</td>\n",
       "      <td>0.972124</td>\n",
       "      <td>0.975221</td>\n",
       "      <td>0.961894</td>\n",
       "      <td>0.978681</td>\n",
       "      <td>0.972375</td>\n",
       "      <td>0.969242</td>\n",
       "      <td>0.968374</td>\n",
       "      <td>0.975955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1.000000   2.633333   4.266667   5.900000   7.533333   9.166667   \\\n",
       "Accuracy    0.999526   0.999561   0.999579   0.999491   0.999579   0.999438   \n",
       "Precision   0.958904   0.948052   0.948718   0.882353   0.926829   0.852273   \n",
       "Recall      0.744681   0.776596   0.787234   0.797872   0.808511   0.797872   \n",
       "F1-Score    0.838323   0.853801   0.860465   0.837989   0.863636   0.824176   \n",
       "ROC_AUC     0.975762   0.982550   0.982295   0.980819   0.980161   0.982035   \n",
       "\n",
       "           10.800000  12.433333  14.066667  15.700000  17.333333  18.966667  \\\n",
       "Accuracy    0.999456   0.999579   0.999561   0.999614   0.999561   0.999561   \n",
       "Precision   0.846154   0.926829   0.925926   0.939024   0.905882   0.905882   \n",
       "Recall      0.819149   0.808511   0.797872   0.819149   0.819149   0.819149   \n",
       "F1-Score    0.832432   0.863636   0.857143   0.875000   0.860335   0.860335   \n",
       "ROC_AUC     0.981581   0.982874   0.976139   0.976336   0.978850   0.982304   \n",
       "\n",
       "           20.600000  22.233333  23.866667  25.500000  27.133333  28.766667  \\\n",
       "Accuracy    0.999579   0.999368   0.999508   0.999438   0.999421   0.999298   \n",
       "Precision   0.926829   0.808511   0.875000   0.836957   0.842697   0.775510   \n",
       "Recall      0.808511   0.808511   0.819149   0.819149   0.797872   0.808511   \n",
       "F1-Score    0.863636   0.808511   0.846154   0.827957   0.819672   0.791667   \n",
       "ROC_AUC     0.983925   0.982381   0.983564   0.971817   0.982663   0.979140   \n",
       "\n",
       "           30.400000  32.033333  33.666667  35.300000  36.933333  38.566667  \\\n",
       "Accuracy    0.999473   0.999438   0.999596   0.999508   0.999350   0.999298   \n",
       "Precision   0.847826   0.836957   0.938272   0.883721   0.800000   0.770000   \n",
       "Recall      0.829787   0.819149   0.808511   0.808511   0.808511   0.819149   \n",
       "F1-Score    0.838710   0.827957   0.868571   0.844444   0.804233   0.793814   \n",
       "ROC_AUC     0.977385   0.965092   0.980089   0.984711   0.972124   0.975221   \n",
       "\n",
       "           40.200000  41.833333  43.466667  45.100000  46.733333  48.366667  \n",
       "Accuracy    0.999315   0.999579   0.999561   0.999526   0.999298   0.999315  \n",
       "Precision   0.777778   0.926829   0.915663   0.894118   0.764706   0.777778  \n",
       "Recall      0.819149   0.808511   0.808511   0.808511   0.829787   0.819149  \n",
       "F1-Score    0.797927   0.863636   0.858757   0.849162   0.795918   0.797927  \n",
       "ROC_AUC     0.961894   0.978681   0.972375   0.969242   0.968374   0.975955  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_weigth = pd.DataFrame(results_weight, index=cols)\n",
    "evaluation_weigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alternate-librarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAEzCAYAAABwueE8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZxUlEQVR4nO3df7Cl9V0f8Pcni4ghkSRKieVHWClmocFs7RZ/ZIhANIImQ+LUArEmjWa264BaG21W2xnvxHG6GnEmTrbu7KQIUSMxRSoNOwEHMEGrE5ZmyQYidgsom20mUJSYREsXP/3jnNXjZc+9Z3fvnt1n7+s1c+ee5/v5fs/5njvznHPf5/s856nuDgAAAMe/FxzrCQAAADAbAQ4AAGAgBDgAAICBEOAAAAAGQoADAAAYCAEOAABgIJYNcFV1Y1V9vqo+PaVeVfXLVbWnqj5VVd80Ubuiqh4Z1zav5MQBAABWm1lW4G5KcsUS9SuTnD/+2ZjkV5KkqtYk2TquX5jk2qq68EgmCwAAsJotG+C6++NJnl6iy1VJPtAjf5TkJVX1dUkuTrKnux/t7meT3DLuCwAAwGFYiXPgzkzyxMT23nHbtHYAAAAOw0krcB91kLZeov3gd1K1MaNDMHPqqaf+03Xr1q3A1AAAAIbngQceeKq7T1/cvhIBbm+Ssye2z0qyL8nJU9oPqru3J9meJBs2bOidO3euwNQAAACGp6r+9GDtK3EI5e1J3jr+NspvSfJMd//vJPcnOb+q1lbVyUmuGfcFAADgMCy7AldVv5nk0iRfW1V7k/xMkq9Iku7elmRHku9OsifJl5O8fVzbX1XXJ7kzyZokN3b3Q0fhOQAAAKwKywa47r52mXonuW5KbUdGAQ8AAIAjtBKHUAIAADAHAhwAAMBACHAAAAADIcABAAAMhAAHAAAwEAIcAADAQAhwAAAAAyHAAQAADIQABwAAMBACHAAAwEAIcAAAAAMhwAEAAAyEAAcAADAQAhwAAMBACHAAAAADIcABAAAMhAAHAAAwEAIcAADAQAhwAAAAAyHAAQAADIQABwAAMBACHAAAwEAIcAAAAAMhwAEAAAyEAAcAADAQAhwAAMBACHAAAAADIcABAAAMhAAHAAAwEAIcAADAQAhwAAAAAyHAAQAADMRJx3oCjJy7+Y4l649v+Z45zQQAADheWYEDAAAYCAEOAABgIAQ4AACAgZgpwFXVFVX1SFXtqarNB6m/tKpuq6pPVdUnqupVE7XHq2p3Ve2qqp0rOXkAAIDVZNkvMamqNUm2JvnOJHuT3F9Vt3f3wxPdfjrJru5+c1WtG/d/3UT9su5+agXnDQAAsOrMsgJ3cZI93f1odz+b5JYkVy3qc2GSu5Oku/84yblVdcaKzhQAAGCVmyXAnZnkiYntveO2SQ8m+d4kqaqLk7wiyVnjWie5q6oeqKqNRzZdAACA1WuW68DVQdp60faWJO+tql1Jdif5ZJL949pruntfVf2DJL9bVX/c3R9/3oOMwt3GJDnnnHNmnD4AAMDqMUuA25vk7Ints5Lsm+zQ3V9I8vYkqapK8tj4J929b/z781V1W0aHZD4vwHX39iTbk2TDhg2LAyJLuOjmi6bWdr9t9xxnAgAAHE2zBLj7k5xfVWuTfDbJNUneMtmhql6S5Mvjc+TekeTj3f2Fqjo1yQu6+y/Ht1+f5N0r+QRWjYXTptfWWrEEAIDVYNkA1937q+r6JHcmWZPkxu5+qKo2jevbklyQ5ANV9VySh5P80Hj4GUluGy3K5aQkH+zuj6780wAAADjxzbICl+7ekWTHorZtE7f/MMn5Bxn3aJJXH+EcAQAAyIwX8gYAAODYE+AAAAAGQoADAAAYCAEOAABgIAQ4AACAgZjpWyhhnl5+766ptc9dtn5u8wAAgOONAAcnoHM33zG19viW75njTAAAWEkOoQQAABgIAQ4AAGAgBDgAAICBEOAAAAAGQoADAAAYCAEOAABgIAQ4AACAgRDgAAAABkKAAwAAGIiTjvUEOLa2brpnau26bZcf9v0uLCwcVu1ouujmi6bWdr9t9xxnsjrdcPUbptbe+aGPzHEmAADDJcAxd3ffc97SHerW+UwEAAAGxiGUAAAAAyHAAQAADIQABwAAMBACHAAAwEAIcAAAAAMhwAEAAAyEAAcAADAQAhwAAMBAuJA3cMzt3XzfkvWztlwyp5kAABzfrMABAAAMhAAHAAAwEAIcAADAQAhwAAAAAyHAAQAADIQABwAAMBACHAAAwEAIcAAAAAPhQt4Myrmb75hae/yUtyw9eO05KzwbAACYLytwAAAAAzFTgKuqK6rqkaraU1WbD1J/aVXdVlWfqqpPVNWrZh0LAADAbJYNcFW1JsnWJFcmuTDJtVV14aJuP51kV3d/Y5K3JnnvIYwFAABgBrOswF2cZE93P9rdzya5JclVi/pcmOTuJOnuP05yblWdMeNYAAAAZjBLgDszyRMT23vHbZMeTPK9SVJVFyd5RZKzZhwLAADADGYJcHWQtl60vSXJS6tqV5IfSfLJJPtnHDt6kKqNVbWzqnY++eSTM0wLAABgdZnlMgJ7k5w9sX1Wkn2THbr7C0neniRVVUkeG/+8cLmxE/exPcn2JNmwYcNBQx4AAMBqNssK3P1Jzq+qtVV1cpJrktw+2aGqXjKuJck7knx8HOqWHQsAAMBsll2B6+79VXV9kjuTrElyY3c/VFWbxvVtSS5I8oGqei7Jw0l+aKmxR+epAAAAnNhmOYQy3b0jyY5Fbdsmbv9hkvNnHQsAAMChmynAARxLCwsLh1UDADjRzHIOHAAAAMcBAQ4AAGAgBDgAAICBEOAAAAAGQoADAAAYCAEOAABgIAQ4AACAgRDgAAAABsKFvGG1WThtmfoz85kHAACHzAocAADAQFiBO8F9Zt0FS3e4dOt8JgIAABwxK3AAAAADIcABAAAMhAAHAAAwEAIcAADAQAhwAAAAA+FbKGEGWzfdM7V23bbL5zgTADg+vPzeXVNrn7ts/dzmAauNFTgAAICBEOAAAAAGQoADAAAYCAEOAABgIAQ4AACAgfAtlAAAcAycu/mOJeuPb/meOc2EIbECBwAAMBACHAAAwEAIcAAAAAMhwAEAAAyELzEBADjObd10z9TaddsuP+z7XVhYOKL60XDRzRdNre1+2+45zmR1uuHqN0ytvfNDH5njTJjGChwAAMBAWIEDAJiDpVaWEqtLwGwEOAAAVtSy1zc75S3Ti2vPWeHZwIlFgAMAAJa1d/N9S9bP2nLJnGayuglwAAAc1N33nDe9WLfObyLA3/IlJgAAAAMhwAEAAAzETIdQVtUVSd6bZE2S93f3lkX105L8epJzxvf5i939q+Pa40n+MslzSfZ394YVmz0AwPFk4bTpNV/OAayAZQNcVa1JsjXJdybZm+T+qrq9ux+e6HZdkoe7+41VdXqSR6rqN7r72XH9su5+aqUnDwAAsJrMsgJ3cZI93f1oklTVLUmuSjIZ4DrJi6uqkrwoydNJ9q/wXJmzG65+w9TaOz/0kTnOBAAASGY7B+7MJE9MbO8dt016X5ILkuxLsjvJj3X334xrneSuqnqgqjYe4XwBAABWrVkCXB2krRdtf1eSXUn+YZL1Sd5XVV89rr2mu78pyZVJrquq1x70Qao2VtXOqtr55JNPzjJ3AACAVWWWQyj3Jjl7YvusjFbaJr09yZbu7iR7quqxJOuSfKK79yVJd3++qm7L6JDMjy9+kO7enmR7kmzYsGFxQAQAAI5jCwsLh1Xj0MwS4O5Pcn5VrU3y2STXJHnLoj5/luR1Se6rqjOSvDLJo1V1apIXdPdfjm+/Psm7V2z2cAJb6uKpr7v8f81xJgAAHC+WDXDdvb+qrk9yZ0aXEbixux+qqk3j+rYkP5vkpqrandEhl+/q7qeq6uuT3Db6bpOclOSD3f3Ro/RcmKO9m+9busMp85kHAMABWzfdM7V23bbL5zgTOHpmug5cd+9IsmNR27aJ2/syWl1bPO7RJK8+wjkCAACQGQMcAAAwZ0tdGH7hmfnNg+PKLN9CCQAAwHHAChwcRcudK3jWlkvmNBMAAE4EVuAAAAAGQoADAAAYCIdQAgDM6NzNdyxZf9xldFadpa7bmrh2KytPgAMAOA58Zt0F04uXbp3fRIDjmgAHR+iGq98wtXb12ncdlcd8+b27lqz7ABgA4MTkHDgAAICBEOAAAAAGQoADAAAYCOfAAQCcwPZuvm960UnTMDhW4AAAAAbCChwAzInrRc1mqb+TvxGw2lmBAwAAGAgrcAAAnPCWum5rkrzzQx85Ko+71LVbnYLI4bACBwAAMBACHAAAwEA4hBIAYMCWOzTw6rXvmtNMgHmwAgcAADAQAhwAAMBACHAAAAAD4Rw4AABWvb2b75taO2vLJXOcCSxNgAPgbx2tf2CWvA7SnZ9dcuzjp7xlenHhmcOcUbJ10z1Ta3/95780tXa0rhWVLP13+txl64/KY35m3QVL1u+5dOvU2nXbLl/p6Sxrqb9RcvT+TgDHC4dQAgAADIQABwAAMBACHAAAwEAIcAAAAAMhwAEAAAyEAAcAADAQAhwAAMBACHAAAAAD4ULekOUvZJslLmQLx5ulLlB9JBdeXlhYOKza0XTRzRdNrf3Wf9y/9OCjtF8v9be45LWHf7/nbr5jam3Ji50nuWjtOVNrv3XYM0puuPoNU2tXr33XkmPff8rdU2tH8nfixOb9GqzAAQAADIYABwAAMBACHAAAwEDMdA5cVV2R5L1J1iR5f3dvWVQ/LcmvJzlnfJ+/2N2/OstYAADg0Cx1DvDut+2e40yYt2VX4KpqTZKtSa5McmGSa6vqwkXdrkvycHe/OsmlSW6oqpNnHAsAAMAMZjmE8uIke7r70e5+NsktSa5a1KeTvLiqKsmLkjydZP+MYwEAAJjBLAHuzCRPTGzvHbdNel+SC5LsS7I7yY9199/MOBYAAIAZzHIOXB2krRdtf1eSXUkuT3Jekt+tqvtmHDt6kKqNSTYmyTnnTL9eDXB0OaYeAOD4NcsK3N4kZ09sn5XRStuktyf57R7Zk+SxJOtmHJsk6e7t3b2huzecfvrps84fAABg1ZhlBe7+JOdX1dokn01yTZK3LOrzZ0lel+S+qjojySuTPJrkL2YYC8Ah+My6C5bucOnWqaUbrn7DkkOvXvuuw5lS7r7nvKU71K2Hdb/Ho72b71u6wynzmQfA4dq66Z5jPYXnefm9u6bWPnfZ+rnNYwiWDXDdvb+qrk9yZ0aXArixux+qqk3j+rYkP5vkpqrandFhk+/q7qeS5GBjj85TAQAAOLHNdB247t6RZMeitm0Tt/clef2sYwEAgNVjNR2pcbTNcg4cAAAAx4GZVuAAAIBhOJJzpTn+WYEDAAAYCCtwAACwhIWFham1S147v3lAYgUOAABgMAQ4AACAgRDgAAAABsI5cADHoYtuvmhq7bfmOA8A4PhiBQ4AAGAgBDgAAICBEOAAAAAGQoADAAAYCAEOAABgIAQ4AACAgRDgAAAABsJ14IAVsXXTPcd6Cs/z8nt3LVn/3GXr5zIPAICVIsABHCsLp02vrT1nfvMAAAZDgINjaGFhYWrtktfObx4AAAyDc+AAAAAGQoADAAAYCAEOAABgIAQ4AACAgfAlJsDMPrPugunFS7fObyIAAKuUFTgAAICBEOAAAAAGQoADAAAYCAEOAABgIHyJCTBod99z3vRi3Tq/iQAAzIEVOAAAgIEQ4AAAAAZCgAMAABgIAQ4AAGAgBDgAAICBEOAAAAAGQoADAAAYCAEOAABgIAQ4AACAgZgpwFXVFVX1SFXtqarNB6n/ZFXtGv98uqqeq6qXjWuPV9XucW3nSj8BAACA1eKk5TpU1ZokW5N8Z5K9Se6vqtu7++EDfbr7PUneM+7/xiQ/3t1PT9zNZd391IrOHAAAYJWZZQXu4iR7uvvR7n42yS1Jrlqi/7VJfnMlJgcAAMDfmSXAnZnkiYntveO256mqFya5IsmtE82d5K6qeqCqNk57kKraWFU7q2rnk08+OcO0AAAAVpdZAlwdpK2n9H1jkj9YdPjka7r7m5JcmeS6qnrtwQZ29/bu3tDdG04//fQZpgUAALC6zBLg9iY5e2L7rCT7pvS9JosOn+zufePfn09yW0aHZAIAAHCIZglw9yc5v6rWVtXJGYW02xd3qqrTknx7kt+ZaDu1ql584HaS1yf59EpMHAAAYLVZ9lsou3t/VV2f5M4ka5Lc2N0PVdWmcX3buOubk9zV3V+aGH5Gktuq6sBjfbC7P7qSTwAAAGC1WDbAJUl370iyY1HbtkXbNyW5aVHbo0lefUQzBBioczffsWT98VPmNBEA4IQx04W8AQAAOPYEOAAAgIEQ4AAAAAZCgAMAABgIAQ4AAGAgBDgAAICBEOAAAAAGQoADAAAYCAEOAABgIAQ4AACAgRDgAAAABkKAAwAAGAgBDgAAYCAEOAAAgIEQ4AAAAAZCgAMAABgIAQ4AAGAgBDgAAICBEOAAAAAGQoADAAAYCAEOAABgIAQ4AACAgRDgAAAABkKAAwAAGAgBDgAAYCAEOAAAgIEQ4AAAAAZCgAMAABgIAQ4AAGAgBDgAAICBEOAAAAAGQoADAAAYCAEOAABgIAQ4AACAgRDgAAAABkKAAwAAGIiZAlxVXVFVj1TVnqrafJD6T1bVrvHPp6vquap62SxjAQAAmM2yAa6q1iTZmuTKJBcmubaqLpzs093v6e713b0+yU8l+Vh3Pz3LWAAAAGYzywrcxUn2dPej3f1skluSXLVE/2uT/OZhjgUAAGCKWQLcmUmemNjeO257nqp6YZIrktx6qGMBAABYWnX30h2qvi/Jd3X3O8bbP5Dk4u7+kYP0vTrJv+zuNx7G2I1JNo43X5nkkcN+VjBfX5vkqWM9CWBF2a/hxGO/Zmhe0d2nL248aYaBe5OcPbF9VpJ9U/pek787fPKQxnb39iTbZ5gPHFeqamd3bzjW8wBWjv0aTjz2a04UsxxCeX+S86tqbVWdnFFIu31xp6o6Lcm3J/mdQx0LAADA8pZdgevu/VV1fZI7k6xJcmN3P1RVm8b1beOub05yV3d/abmxK/0kAAAAVoNlz4EDllZVG8eHAAMnCPs1nHjs15woBDgAAICBmOUcOAAAAI4DAhyrSlU9V1W7qurTVfXh8bULj/Q+311V37FEfVNVvfVIHwc4dIv2+f9WVS9Z4ft/vKq+dnz7iyt537DaTey/B37Oraqvqap7q+qLVfW+Jca+sKp+o6p2j/f/36+qF81z/nC0OISSVaWqvtjdLxrf/o0kD3T3L03U13T3c8dsgsCKWrTP35zkT7r751bw/h9PsqG7n5p8LODIHWyfqqpTk/yTJK9K8qruvn7K2J9Kcnp3/9vx9iuTPN7d//cI5nNSd+8/3PGwUqzAsZrdl+QfVdWl40/zPphkd1Wtqar3VNX9VfWpqvrXBwZU1b8bf5r3YFVtGbfdVFX/fHx7S1U9PB73i+O2har6ifHt9VX1R+P6bVX10nH771XVz1fVJ6rqT6rqknn/MWAV+MMkZyZJVZ1XVR+tqgeq6r6qWjduP2O8bz44/vm2cft/Hfd9qKo2HsPnAKtad3+pu38/yV8v0/Xrknx2YtwjB8JbVb11/D78YFX92rjtFVV197j97qo6Z9x+U1X9UlXdm+Tnp712wDzNciFvOOFU1UlJrkzy0XHTxRl9kvfY+J+zZ7r7n1XVVyb5g6q6K8m6JG9K8s3d/eWqetmi+3xZRpfTWNfdPeVQrQ8k+ZHu/lhVvTvJzyT5N+PaSd19cVV997h96mGZwKGpqjVJXpfkP4+btifZ1N3/s6q+Ocl/SnJ5kl9O8rHufvN4zIFP/3+wu5+uqq9Kcn9V3drd/2fOTwNWm6+qql3j249195sPYeyNSe4af8B6d5Kbx/v7P07y75O8ZrxyfuC9/H1JPtDdN1fVD2b0WvCmce0bknxHdz9XVXfn4K8dMDcCHKvN5JvBfRn9M/dtST7R3Y+N21+f5BsPrKolOS3J+RkFql/t7i8nSXc/vei+v5DRJ4Lvr6o7knxksliji92/pLs/Nm66OcmHJ7r89vj3A0nOPdwnCPw9B/b5czPat353fB7MtyX5cFUd6PeV49+XJ3lrkowPp35m3P6jVXXgn8ezM3pNEODg6Pqr7l5/OAO7e1dVfX1G7+nfkdEHL9+a0T7+X7r7qXG/A+/l35rke8e3fy3JL0zc3YfH4W2p1w6YGwGO1eZ5bwbjF+EvTTZltEp256J+VySZetLo+ML1F2f0Kf81Sa7PoX0qd+C4/Odi34SV8lfdvX78AcpHklyX5KYkfzHrP4ZVdWlG/wB+63j1/feSnHI0JgscnvEHLD8z3nxHd+/s7i9m9OHob1fV3yT57iT/L0u8l0+Y7HPgf4QX5BBeO+BocQ4cPN+dSX64qr4iSarqG8YnTd+V5Adr/M2VBzmE8kVJTuvuHRkdFrl+st7dzyT584nz234gyccCHHXj/e9Hk/xEkr9K8lhVfV+S1Mirx13vTvLD4/Y1VfXVGa3C//k4vK1L8i1zfwLAkrr7tu5eP/7ZWVWvmTjP/OQkFyb504z28X9RVV8zrh14L//vGX34miTfn+T3D/IYX8j01w6YG5/yw/O9P6PDrf5HjZbnnkzypu7+aFWtT7Kzqp5NsiPJT0+Me3GS36mqUzJaxfvxg9z325JsG4fAR5O8/ag9C+Dv6e5PVtWDGf2T9v1JfqWq/kOSr0hyS5IHk/xYku1V9UMZrYb/cEbnym6qqk8leSTJHx2L+QMjNfr2169OcnJVvSnJ67v74UXdzstoH6+MFizuSHLr+Bz1n0vysap6Lsknk/yrjD7gubGqfjKj9/1p78/TXjtgblxGAAAAYCAcQgkAADAQAhwAAMBACHAAAAADIcABAAAMhAAHAAAwEAIcAADAQAhwAAAAAyHAAQAADMT/B9XTNm4d6VSqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = evaluation_weigth.loc[['Precision', 'Recall', 'F1-Score']]\n",
    "data.plot(kind=\"bar\", figsize=(15, 5), width=0.9, rot=0, legend=False)\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
