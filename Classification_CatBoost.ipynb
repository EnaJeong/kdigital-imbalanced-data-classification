{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "occupational-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import *\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "monthly-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-edinburgh",
   "metadata": {},
   "source": [
    "# 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subject-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./datasets/X_samples.pickle\", \"rb\") as f:\n",
    "    X_samples = pickle.load(f)\n",
    "    \n",
    "with open(f\"./datasets/y_samples.pickle\", \"rb\") as f:\n",
    "    y_samples = pickle.load(f)\n",
    "    \n",
    "with open(f\"./datasets/X_test.pickle\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "    \n",
    "with open(f\"./datasets/y_test.pickle\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cellular-carry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201810</th>\n",
       "      <td>0.579847</td>\n",
       "      <td>-0.011862</td>\n",
       "      <td>1.035499</td>\n",
       "      <td>-0.317540</td>\n",
       "      <td>0.216728</td>\n",
       "      <td>1.201270</td>\n",
       "      <td>-0.537323</td>\n",
       "      <td>1.319719</td>\n",
       "      <td>-0.189181</td>\n",
       "      <td>-0.627079</td>\n",
       "      <td>-0.131042</td>\n",
       "      <td>0.186976</td>\n",
       "      <td>0.428736</td>\n",
       "      <td>-0.650821</td>\n",
       "      <td>0.607427</td>\n",
       "      <td>-1.605008</td>\n",
       "      <td>-0.426110</td>\n",
       "      <td>-0.604022</td>\n",
       "      <td>0.099792</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.286629</td>\n",
       "      <td>0.166828</td>\n",
       "      <td>0.550873</td>\n",
       "      <td>-0.323683</td>\n",
       "      <td>-0.402491</td>\n",
       "      <td>0.195611</td>\n",
       "      <td>-0.573086</td>\n",
       "      <td>-0.079200</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>-0.254035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264506</th>\n",
       "      <td>0.901937</td>\n",
       "      <td>2.267601</td>\n",
       "      <td>-1.634754</td>\n",
       "      <td>-2.368609</td>\n",
       "      <td>-2.592182</td>\n",
       "      <td>1.161092</td>\n",
       "      <td>3.434814</td>\n",
       "      <td>-1.615728</td>\n",
       "      <td>0.797080</td>\n",
       "      <td>-1.404452</td>\n",
       "      <td>1.591339</td>\n",
       "      <td>-0.219360</td>\n",
       "      <td>-0.722225</td>\n",
       "      <td>0.316331</td>\n",
       "      <td>-0.203926</td>\n",
       "      <td>0.188359</td>\n",
       "      <td>-0.707386</td>\n",
       "      <td>0.435844</td>\n",
       "      <td>-0.286008</td>\n",
       "      <td>-0.261407</td>\n",
       "      <td>-0.343678</td>\n",
       "      <td>-0.163936</td>\n",
       "      <td>-0.078568</td>\n",
       "      <td>0.259323</td>\n",
       "      <td>0.687408</td>\n",
       "      <td>-0.131926</td>\n",
       "      <td>-0.141368</td>\n",
       "      <td>0.026772</td>\n",
       "      <td>-0.055990</td>\n",
       "      <td>0.041920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63736</th>\n",
       "      <td>-0.397573</td>\n",
       "      <td>1.118301</td>\n",
       "      <td>-1.260762</td>\n",
       "      <td>0.981093</td>\n",
       "      <td>-0.380698</td>\n",
       "      <td>-1.876228</td>\n",
       "      <td>-0.490142</td>\n",
       "      <td>-1.089500</td>\n",
       "      <td>0.062601</td>\n",
       "      <td>0.119233</td>\n",
       "      <td>0.495179</td>\n",
       "      <td>-0.818852</td>\n",
       "      <td>-1.269072</td>\n",
       "      <td>-1.259742</td>\n",
       "      <td>-0.383677</td>\n",
       "      <td>0.541024</td>\n",
       "      <td>1.271092</td>\n",
       "      <td>0.402624</td>\n",
       "      <td>-0.814504</td>\n",
       "      <td>0.430227</td>\n",
       "      <td>0.227343</td>\n",
       "      <td>0.364685</td>\n",
       "      <td>0.773901</td>\n",
       "      <td>-0.193256</td>\n",
       "      <td>0.415118</td>\n",
       "      <td>0.360261</td>\n",
       "      <td>-0.054869</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>0.043857</td>\n",
       "      <td>1.553832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241327</th>\n",
       "      <td>0.778757</td>\n",
       "      <td>2.063018</td>\n",
       "      <td>0.608260</td>\n",
       "      <td>-3.168853</td>\n",
       "      <td>0.618313</td>\n",
       "      <td>1.228515</td>\n",
       "      <td>-1.367266</td>\n",
       "      <td>0.683151</td>\n",
       "      <td>-0.308130</td>\n",
       "      <td>-0.147176</td>\n",
       "      <td>-0.859443</td>\n",
       "      <td>1.672501</td>\n",
       "      <td>0.060919</td>\n",
       "      <td>-0.917332</td>\n",
       "      <td>-2.099999</td>\n",
       "      <td>-0.637629</td>\n",
       "      <td>0.540038</td>\n",
       "      <td>1.976581</td>\n",
       "      <td>1.105321</td>\n",
       "      <td>-0.025014</td>\n",
       "      <td>-0.155587</td>\n",
       "      <td>-0.022321</td>\n",
       "      <td>0.076885</td>\n",
       "      <td>-0.042470</td>\n",
       "      <td>0.578092</td>\n",
       "      <td>0.345450</td>\n",
       "      <td>0.660782</td>\n",
       "      <td>-0.089294</td>\n",
       "      <td>-0.023863</td>\n",
       "      <td>-0.296793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271841</th>\n",
       "      <td>0.940836</td>\n",
       "      <td>-1.212528</td>\n",
       "      <td>0.730185</td>\n",
       "      <td>1.549615</td>\n",
       "      <td>-0.954037</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>-0.092019</td>\n",
       "      <td>0.124386</td>\n",
       "      <td>0.595537</td>\n",
       "      <td>-0.570630</td>\n",
       "      <td>-1.090583</td>\n",
       "      <td>0.339272</td>\n",
       "      <td>0.843626</td>\n",
       "      <td>0.394601</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>-0.512564</td>\n",
       "      <td>0.792514</td>\n",
       "      <td>-0.751414</td>\n",
       "      <td>0.277571</td>\n",
       "      <td>0.372448</td>\n",
       "      <td>-0.012042</td>\n",
       "      <td>-0.161695</td>\n",
       "      <td>-0.744489</td>\n",
       "      <td>-0.173554</td>\n",
       "      <td>-0.405409</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>-0.143519</td>\n",
       "      <td>-0.050795</td>\n",
       "      <td>0.034654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "201810  0.579847 -0.011862  1.035499 -0.317540  0.216728  1.201270 -0.537323   \n",
       "264506  0.901937  2.267601 -1.634754 -2.368609 -2.592182  1.161092  3.434814   \n",
       "63736  -0.397573  1.118301 -1.260762  0.981093 -0.380698 -1.876228 -0.490142   \n",
       "241327  0.778757  2.063018  0.608260 -3.168853  0.618313  1.228515 -1.367266   \n",
       "271841  0.940836 -1.212528  0.730185  1.549615 -0.954037  0.008643 -0.092019   \n",
       "\n",
       "              V7        V8        V9       V10       V11       V12       V13  \\\n",
       "201810  1.319719 -0.189181 -0.627079 -0.131042  0.186976  0.428736 -0.650821   \n",
       "264506 -1.615728  0.797080 -1.404452  1.591339 -0.219360 -0.722225  0.316331   \n",
       "63736  -1.089500  0.062601  0.119233  0.495179 -0.818852 -1.269072 -1.259742   \n",
       "241327  0.683151 -0.308130 -0.147176 -0.859443  1.672501  0.060919 -0.917332   \n",
       "271841  0.124386  0.595537 -0.570630 -1.090583  0.339272  0.843626  0.394601   \n",
       "\n",
       "             V14       V15       V16       V17       V18       V19       V20  \\\n",
       "201810  0.607427 -1.605008 -0.426110 -0.604022  0.099792  0.000011 -0.286629   \n",
       "264506 -0.203926  0.188359 -0.707386  0.435844 -0.286008 -0.261407 -0.343678   \n",
       "63736  -0.383677  0.541024  1.271092  0.402624 -0.814504  0.430227  0.227343   \n",
       "241327 -2.099999 -0.637629  0.540038  1.976581  1.105321 -0.025014 -0.155587   \n",
       "271841  0.266667 -0.512564  0.792514 -0.751414  0.277571  0.372448 -0.012042   \n",
       "\n",
       "             V21       V22       V23       V24       V25       V26       V27  \\\n",
       "201810  0.166828  0.550873 -0.323683 -0.402491  0.195611 -0.573086 -0.079200   \n",
       "264506 -0.163936 -0.078568  0.259323  0.687408 -0.131926 -0.141368  0.026772   \n",
       "63736   0.364685  0.773901 -0.193256  0.415118  0.360261 -0.054869  0.016690   \n",
       "241327 -0.022321  0.076885 -0.042470  0.578092  0.345450  0.660782 -0.089294   \n",
       "271841 -0.161695 -0.744489 -0.173554 -0.405409  0.217600  0.357895 -0.143519   \n",
       "\n",
       "             V28    Amount  \n",
       "201810  0.015847 -0.254035  \n",
       "264506 -0.055990  0.041920  \n",
       "63736   0.043857  1.553832  \n",
       "241327 -0.023863 -0.296793  \n",
       "271841 -0.050795  0.034654  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "external-mistake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201810    0\n",
       "264506    0\n",
       "63736     0\n",
       "241327    0\n",
       "271841    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "racial-turkish",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Raw\n",
      "====================================================================================================\n",
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "143144  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "258914  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "51111  -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "146949  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "135606 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "              V7        V8        V9       V10       V11       V12       V13  \\\n",
      "143144  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "258914 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "51111  -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "146949  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "135606  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "             V14       V15       V16       V17       V18       V19       V20  \\\n",
      "143144 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "258914 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "51111  -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "146949  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "135606 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "             V21       V22       V23       V24       V25       V26       V27  \\\n",
      "143144 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "258914 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "51111   0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "146949 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "135606 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "             V28    Amount  \n",
      "143144 -0.093342 -0.296793  \n",
      "258914 -0.041962  0.565919  \n",
      "51111   0.240607 -0.296793  \n",
      "146949  0.223898 -0.237546  \n",
      "135606  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0    227447\n",
      "1       398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 227845\n",
      "0 비율 :  99.83 %\n",
      "1 비율 :   0.17 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "SMOTE\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "1  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "2 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "3  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "1 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "2 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "3  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "1 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "2 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "3  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "1 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "2  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "3 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0 -0.093342 -0.296793  \n",
      "1 -0.041962  0.565919  \n",
      "2  0.240607 -0.296793  \n",
      "3  0.223898 -0.237546  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0    227447\n",
      "1    227447\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 454894\n",
      "0 비율 :  50.00 %\n",
      "1 비율 :  50.00 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "ADASYN\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "1  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "2 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "3  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "1 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "2 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "3  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "1 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "2 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "3  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "1 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "2  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "3 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0 -0.093342 -0.296793  \n",
      "1 -0.041962  0.565919  \n",
      "2  0.240607 -0.296793  \n",
      "3  0.223898 -0.237546  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    227453\n",
      "0    227447\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 454900\n",
      "1 비율 :  50.00 %\n",
      "0 비율 :  50.00 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "CNN\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.989403 -0.147206  1.099073 -0.448814 -0.670465  0.813368 -0.624680   \n",
      "1  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "2  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "3 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.824100  0.068627 -0.036771 -0.339651  1.049736  0.317577 -0.675746   \n",
      "1  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "2 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "3 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -0.768674 -0.869056  0.497980  0.186416  0.290770 -0.013677  0.109644   \n",
      "1 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "2 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "3 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.320720 -0.768440  0.111616  0.642187 -0.437602  0.093575  0.327780   \n",
      "1 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "2 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "3  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0  0.130896 -0.211835  \n",
      "1 -0.093342 -0.296793  \n",
      "2 -0.041962  0.565919  \n",
      "3  0.240607 -0.296793  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0    908\n",
      "1    398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 1306\n",
      "0 비율 :  69.53 %\n",
      "1 비율 :  30.47 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "SMOTE + ENN\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "1  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "2 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "3  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "1 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "2 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "3  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "1 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "2 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "3  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "1 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "2  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "3 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0 -0.093342 -0.296793  \n",
      "1 -0.041962  0.565919  \n",
      "2  0.240607 -0.296793  \n",
      "3  0.223898 -0.237546  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    227447\n",
      "0    227056\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 454503\n",
      "1 비율 :  50.04 %\n",
      "0 비율 :  49.96 %\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "ADASYN + ENN\n",
      "====================================================================================================\n",
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0  0.005428 -0.540939  0.637584  2.439590  1.316115  0.742650  1.671102   \n",
      "1  0.871545  1.923123 -1.555096  0.211476 -0.174906 -1.760650  0.456333   \n",
      "2 -0.468709 -1.939810 -1.039497  0.429346 -0.198014  2.693946 -2.792994   \n",
      "3  0.038652 -0.801246  1.067120  0.506310 -2.533708  0.597024 -1.446026   \n",
      "4 -0.039556 -0.280807  1.109719  0.944761 -0.132693  0.423860 -0.509289   \n",
      "\n",
      "         V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0  0.280149  0.293844  0.026988 -0.120361 -1.040090  1.148056  1.069975   \n",
      "1 -1.652432  0.375407  0.892833  0.788104 -0.439165  0.143663 -1.216406   \n",
      "2 -0.279832  0.114651 -0.089721 -1.381296  0.012582 -0.794746 -1.833108   \n",
      "3  1.376331 -0.269470  0.208041 -0.934162 -0.882872  0.294591  0.305609   \n",
      "4  0.698370 -0.020385 -0.333794 -0.510310 -0.965409 -0.370223  0.236423   \n",
      "\n",
      "        V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0 -1.459141 -3.824216  0.491091 -1.028001  0.063102 -0.238231 -0.055148   \n",
      "1 -0.490535 -1.399096 -1.090021 -0.139776  1.841343 -0.211423 -0.579051   \n",
      "2 -1.042923  0.078999  0.731580  0.874212 -0.062750 -2.448978  0.138139   \n",
      "3  0.004751 -0.519378  0.256430 -0.860309 -0.884299 -0.800661  0.057025   \n",
      "4 -0.473865  0.957233  0.627924 -0.294280  0.137636  0.224564  0.138997   \n",
      "\n",
      "        V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0 -0.270409 -0.238482 -0.338757 -1.002661 -0.060379 -0.276043 -0.001160   \n",
      "1 -0.393833 -0.502683  0.288658 -0.366769 -0.662372  0.528734  0.010908   \n",
      "2  0.194420 -0.143151  0.354888  0.213072 -0.471635 -0.058909  0.034189   \n",
      "3 -0.315741 -0.753499 -0.129894 -0.093705 -0.003377  0.381592  0.337806   \n",
      "4 -0.319014 -0.844576 -0.118004 -0.520341 -0.049944  0.124567  0.244372   \n",
      "\n",
      "        V28    Amount  \n",
      "0 -0.093342 -0.296793  \n",
      "1 -0.041962  0.565919  \n",
      "2  0.240607 -0.296793  \n",
      "3  0.223898 -0.237546  \n",
      "4  0.089572 -0.253336  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    227453\n",
      "0    227056\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "Total : 454509\n",
      "1 비율 :  50.04 %\n",
      "0 비율 :  49.96 %\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for key, sample in X_samples.items():\n",
    "    y = y_samples[key]\n",
    "    total = len(y)\n",
    "    counts = y.value_counts()\n",
    "    \n",
    "    print('=' * 100)\n",
    "    print(key)\n",
    "    print('=' * 100)\n",
    "    print(sample.head())\n",
    "    print('-' * 100)\n",
    "    print(counts)\n",
    "    print('-' * 30)\n",
    "    print(f\"Total : {total}\")\n",
    "    for idx in counts.index:\n",
    "        print(f\"{idx} 비율 : {counts[idx] / total * 100:6.2f} %\")\n",
    "    print('=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-electron",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quantitative-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data_info(y):\n",
    "    total = len(y)\n",
    "    counts = y.value_counts()\n",
    "    print('=' * 80)\n",
    "    print(counts)\n",
    "    print('-' * 30)\n",
    "    for idx in counts.index:\n",
    "        print(f\"{idx} 비율 : {counts[idx] / total * 100:6.2f} %\")\n",
    "    print('=' * 80)\n",
    "\n",
    "def evaluate_model(clf, x_test, y_test):\n",
    "    y_proba = clf.predict_proba(x_test)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    fl = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "    \n",
    "    print('=' * 80)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('-' * 60)\n",
    "    print(f'Accuracy  : {accuracy}')\n",
    "    print(f'Precision : {precision}')\n",
    "    print(f'Recall    : {recall}')\n",
    "    print(f'F1-Score  : {fl}')\n",
    "    print('-' * 60)\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print('-' * 60)\n",
    "    print(f'ROC AUC : {roc_auc}')\n",
    "    print('=' * 80)\n",
    "    \n",
    "    return accuracy, precision, recall, fl, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recreational-absolute",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Raw\n",
      "================================================================================\n",
      "0    227447\n",
      "1       398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  99.83 %\n",
      "1 비율 :   0.17 %\n",
      "================================================================================\n",
      "CatBoost Raw\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56866     2]\n",
      " [   25    69]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995259997893332\n",
      "Precision : 0.971830985915493\n",
      "Recall    : 0.7340425531914894\n",
      "F1-Score  : 0.8363636363636363\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.97      0.73      0.84        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.87      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9760256675032438\n",
      "================================================================================\n",
      "================================================================================\n",
      "SMOTE\n",
      "================================================================================\n",
      "0    227447\n",
      "1    227447\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  50.00 %\n",
      "1 비율 :  50.00 %\n",
      "================================================================================\n",
      "CatBoost SMOTE\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56801    67]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9985077771145676\n",
      "Precision : 0.5314685314685315\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.6413502109704642\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.53      0.81      0.64        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.77      0.90      0.82     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9765169133746084\n",
      "================================================================================\n",
      "================================================================================\n",
      "ADASYN\n",
      "================================================================================\n",
      "1    227453\n",
      "0    227447\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "1 비율 :  50.00 %\n",
      "0 비율 :  50.00 %\n",
      "================================================================================\n",
      "CatBoost ADASYN\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56763   105]\n",
      " [   16    78]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9978757768336786\n",
      "Precision : 0.4262295081967213\n",
      "Recall    : 0.8297872340425532\n",
      "F1-Score  : 0.5631768953068592\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.43      0.83      0.56        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.71      0.91      0.78     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9807061593926361\n",
      "================================================================================\n",
      "================================================================================\n",
      "CNN\n",
      "================================================================================\n",
      "0    908\n",
      "1    398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  69.53 %\n",
      "1 비율 :  30.47 %\n",
      "================================================================================\n",
      "CatBoost CNN\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56856    12]\n",
      " [   18    76]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9994733330992591\n",
      "Precision : 0.8636363636363636\n",
      "Recall    : 0.8085106382978723\n",
      "F1-Score  : 0.8351648351648351\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.86      0.81      0.84        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.90      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9779863483782525\n",
      "================================================================================\n",
      "================================================================================\n",
      "SMOTE + ENN\n",
      "================================================================================\n",
      "1    227447\n",
      "0    227056\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "1 비율 :  50.04 %\n",
      "0 비율 :  49.96 %\n",
      "================================================================================\n",
      "CatBoost SMOTE + ENN\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56789    79]\n",
      " [   16    78]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9983322214809873\n",
      "Precision : 0.4968152866242038\n",
      "Recall    : 0.8297872340425532\n",
      "F1-Score  : 0.6215139442231075\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.50      0.83      0.62        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.75      0.91      0.81     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9766699366506086\n",
      "================================================================================\n",
      "================================================================================\n",
      "ADASYN + ENN\n",
      "================================================================================\n",
      "1    227453\n",
      "0    227056\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "1 비율 :  50.04 %\n",
      "0 비율 :  49.96 %\n",
      "================================================================================\n",
      "CatBoost ADASYN + ENN\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56796    72]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9984375548611355\n",
      "Precision : 0.5167785234899329\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.6337448559670781\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.52      0.82      0.63        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.76      0.91      0.82     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9767788114019925\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "clfs, results = {}, {}\n",
    "accuracies, precisions, recalls, f1_scores, roc_aucs = {}, {}, {}, {}, {}\n",
    "\n",
    "for key, X in X_samples.items():\n",
    "    y = y_samples[key]\n",
    "    \n",
    "    print('=' * 80)\n",
    "    print(key)\n",
    "    show_data_info(y)\n",
    "    \n",
    "    clf = CatBoostClassifier(learning_rate=0.1, eval_metric='F1', early_stopping_rounds=100, verbose=False)\n",
    "    clf.fit(X, y, eval_set=(X_test, y_test))\n",
    "    \n",
    "    print(f'CatBoost {key}')\n",
    "    result = evaluate_model(clf, X_test, y_test)\n",
    "    \n",
    "    clfs[key] = clf\n",
    "    results[key] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "august-advance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Raw\n",
      "================================================================================\n",
      "0    227447\n",
      "1       398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  99.83 %\n",
      "1 비율 :   0.17 %\n",
      "================================================================================\n",
      "CatBoost Balanced\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[54916  1952]\n",
      " [   10    84]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9655559846915488\n",
      "Precision : 0.0412573673870334\n",
      "Recall    : 0.8936170212765957\n",
      "F1-Score  : 0.07887323943661971\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     56868\n",
      "           1       0.04      0.89      0.08        94\n",
      "\n",
      "    accuracy                           0.97     56962\n",
      "   macro avg       0.52      0.93      0.53     56962\n",
      "weighted avg       1.00      0.97      0.98     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9691341015176618\n",
      "================================================================================\n",
      "================================================================================\n",
      "Raw\n",
      "================================================================================\n",
      "0    227447\n",
      "1       398\n",
      "Name: Class, dtype: int64\n",
      "------------------------------\n",
      "0 비율 :  99.83 %\n",
      "1 비율 :   0.17 %\n",
      "================================================================================\n",
      "CatBoost SqrtBalanced\n",
      "================================================================================\n",
      "Confusion Matrix\n",
      "[[56862     6]\n",
      " [   17    77]]\n",
      "------------------------------------------------------------\n",
      "Accuracy  : 0.9995962220427653\n",
      "Precision : 0.927710843373494\n",
      "Recall    : 0.8191489361702128\n",
      "F1-Score  : 0.8700564971751413\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.93      0.82      0.87        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.96      0.91      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "------------------------------------------------------------\n",
      "ROC AUC : 0.9836697226425062\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "class_weights = ['Balanced', 'SqrtBalanced']\n",
    "\n",
    "for class_weight in class_weights:\n",
    "    X, y = X_samples['Raw'], y_samples['Raw']\n",
    "    \n",
    "    print('=' * 80)\n",
    "    print('Raw')\n",
    "    show_data_info(y)\n",
    "    \n",
    "    clf = CatBoostClassifier(learning_rate=0.1, eval_metric='F1', auto_class_weights=class_weight,\n",
    "                             early_stopping_rounds=100, verbose=False)\n",
    "    clf.fit(X, y, eval_set=(X_test, y_test))\n",
    "    \n",
    "    print(f'CatBoost {class_weight}')\n",
    "    result = evaluate_model(clf, X_test, y_test)\n",
    "    \n",
    "    clfs[class_weight] = clf\n",
    "    results[class_weight] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "perfect-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raw</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.976026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.998508</td>\n",
       "      <td>0.531469</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.641350</td>\n",
       "      <td>0.976517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.997876</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.563177</td>\n",
       "      <td>0.980706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.835165</td>\n",
       "      <td>0.977986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE + ENN</td>\n",
       "      <td>0.998332</td>\n",
       "      <td>0.496815</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.621514</td>\n",
       "      <td>0.976670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADASYN + ENN</td>\n",
       "      <td>0.998438</td>\n",
       "      <td>0.516779</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.633745</td>\n",
       "      <td>0.976779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>0.965556</td>\n",
       "      <td>0.041257</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.078873</td>\n",
       "      <td>0.969134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SqrtBalanced</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.983670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Accuracy  Precision    Recall  F1-Score   ROC_AUC\n",
       "0           Raw  0.999526   0.971831  0.734043  0.836364  0.976026\n",
       "1         SMOTE  0.998508   0.531469  0.808511  0.641350  0.976517\n",
       "2        ADASYN  0.997876   0.426230  0.829787  0.563177  0.980706\n",
       "3           CNN  0.999473   0.863636  0.808511  0.835165  0.977986\n",
       "4   SMOTE + ENN  0.998332   0.496815  0.829787  0.621514  0.976670\n",
       "5  ADASYN + ENN  0.998438   0.516779  0.819149  0.633745  0.976779\n",
       "6      Balanced  0.965556   0.041257  0.893617  0.078873  0.969134\n",
       "7  SqrtBalanced  0.999596   0.927711  0.819149  0.870056  0.983670"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC_AUC']\n",
    "    \n",
    "evaluation = pd.DataFrame.from_dict(results, orient='index', columns=cols)\n",
    "evaluation.index.set_names('Model', inplace=True)\n",
    "evaluation.reset_index(inplace=True)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "offensive-airline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation.plot(x=\"Model\", y=cols, kind=\"bar\", figsize=(10, 5))\n",
    "plt.legend(loc=(1.01, 0.))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
